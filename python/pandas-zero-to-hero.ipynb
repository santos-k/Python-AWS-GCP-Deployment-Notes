{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pandas\n**Pandas** is a powerful and popular open-source Python library for data manipulation and analysis. It is built on top of NumPy and provides easy-to-use data structures and functions for working with structured data, making it an essential tool in the data science and data analysis toolkit. Here's a more detailed explanation of what pandas is and what it offers:\n\n1. **Data Structures:**\n   - **DataFrame:** The primary data structure in pandas is the DataFrame, which is a 2-dimensional, size-mutable, and tabular data structure. Think of it as a table or spreadsheet where you can store and manipulate data. Each column in a DataFrame is a Series, which is a one-dimensional labeled array with data of any type.\n   \n2. **Key Features:**\n   - **Data Loading:** Pandas can read data from various sources, including CSV files, Excel spreadsheets, SQL databases, and more. It can also connect to online data sources, making it versatile for data ingestion.\n   - **Data Cleaning:** It provides powerful tools for handling missing data, transforming data, and dealing with outliers.\n   - **Data Indexing and Selection:** Pandas offers flexible indexing methods, including label-based, integer-based, and Boolean-based indexing, allowing you to select and filter data easily.\n   - **Data Aggregation and Grouping:** You can group and aggregate data based on certain criteria using pandas, which is essential for performing summary statistics and analysis.\n   - **Merging and Joining:** Pandas can merge and join datasets similar to SQL databases, enabling you to combine data from multiple sources.\n   - **Time Series Analysis:** It has built-in support for time series data, making it suitable for financial and temporal data analysis.\n   - **Data Visualization:** While pandas is primarily a data manipulation library, it can also work seamlessly with data visualization libraries like Matplotlib and Seaborn for creating charts and plots.\n\n3. **Use Cases:**\n   - **Data Analysis:** Pandas is widely used for data exploration and analysis, allowing data scientists and analysts to perform tasks like data cleaning, transformation, and statistical analysis.\n   - **Data Preparation:** Before feeding data into machine learning models, you often need to preprocess and structure it correctly. Pandas is invaluable for this purpose.\n   - **Data Wrangling:** When working with real-world data, it's common to have data in messy formats. Pandas helps clean and prepare this data for analysis.\n   - **Data Reporting and Visualization:** While not a data visualization library in itself, pandas can be combined with libraries like Matplotlib and Seaborn to create informative visualizations.\n\n4. **Community and Documentation:**\n   - Pandas has a large and active community, which means that there is plenty of support, documentation, and online resources available. This makes it easy to find solutions to common data-related problems.\n\nIn summary, pandas is an indispensable tool for data manipulation and analysis in Python. It simplifies the handling of structured data, making it more accessible for users to perform various data-related tasks, from basic data cleaning to complex data analysis.\n","metadata":{}},{"cell_type":"markdown","source":"Pandas provides a wide range of functions and methods for data manipulation and analysis. Here's a list of some of the most commonly used basic functions and methods in pandas:\n\n**DataFrame and Series Creation:**\n1. `pd.DataFrame(data)`: Create a new DataFrame from data (e.g., a dictionary or a 2D array).\n2. `pd.Series(data)`: Create a new Series from data.\n\n**Data Loading and Input/Output:**\n\n3. `pd.read_csv(filename)`: Read data from a CSV file.\n4. `pd.read_excel(filename)`: Read data from an Excel file.\n5. `pd.read_sql(query, connection)`: Read data from a SQL database.\n6. `df.to_csv(filename)`: Write data to a CSV file.\n7. `df.to_excel(filename)`: Write data to an Excel file.\n\n**Data Exploration and Information:**\n\n8. `df.head(n)`: Display the first n rows of the DataFrame.\n9. `df.tail(n)`: Display the last n rows of the DataFrame.\n10. `df.info()`: Display information about the DataFrame, including data types and missing values.\n11. `df.describe()`: Generate summary statistics of the DataFrame.\n12. `df.shape`: Get the dimensions (rows, columns) of the DataFrame.\n\n**Indexing and Selection:**\n\n13. `df[column]`: Select a single column by name.\n14. `df[[column1, column2]]`: Select multiple columns by name.\n15. `df.iloc[row, column]`: Select data by integer-based location.\n16. `df.loc[row_label, column_label]`: Select data by label-based location.\n\n**Data Cleaning and Transformation:**\n\n17. `df.drop(labels, axis)`: Remove rows or columns.\n18. `df.fillna(value)`: Fill missing values with a specified value.\n19. `df.dropna()`: Remove rows with missing values.\n20. `df.rename(columns)`: Rename columns.\n21. `df.sort_values(by)`: Sort DataFrame by column(s).\n22. `df.groupby(column)`: Group data based on a column.\n23. `df.pivot_table()`: Create a pivot table.\n\n**Filtering and Querying:**\n\n24. `df[df['column'] > value]`: Filter data based on a condition.\n25. `df.query('condition')`: Query data using a SQL-like syntax.\n\n**Aggregation and Statistics:**\n\n26. `df.mean()`, `df.median()`, `df.sum()`, `df.min()`, `df.max()`: Compute various statistics.\n27. `df.groupby(column).agg(func)`: Perform custom aggregation.\n\n**Data Visualization:**\n\n28. `df.plot()`: Create basic plots using Matplotlib.\n29. `df.hist()`, `df.plot.hist()`: Create histograms.\n30. `df.plot.scatter()`: Create scatter plots.\n\n**Merging and Joining:**\n\n31. `pd.concat([df1, df2])`: Concatenate DataFrames.\n32. `df1.merge(df2, on='key')`: Perform SQL-like joins.\n\n**Time Series and Datetime Handling:**\n\n33. `pd.to_datetime(series)`: Convert a series to datetime.\n34. `df.resample('D').sum()`: Resample time series data.\n\n**Serialization:**\n\n35. `df.to_pickle(filename)`: Serialize the DataFrame to a pickle file.\n36. `pd.read_pickle(filename)`: Deserialize a pickle file to a DataFrame.\n\nThese are some of the basic functions and methods in pandas. The library offers many more functions for specialized data operations, so be sure to consult the official pandas documentation for more detailed information and examples.","metadata":{}},{"cell_type":"markdown","source":"# DataFrame and Series Creation:\n### 1. Series Creation\n\nCertainly! To create Pandas Series from various data sources, including lists, tuples, dictionaries, JSON, strings, and NumPy arrays, you can use the `pd.Series()` constructor or simply access a specific column of a DataFrame. Here are examples for each data source:\n\n#### **1. From a List:**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n# Create a Pandas Series from a list\ndata_list = [1, 2, 3, 4, 5]\nseries_from_list = pd.Series(data_list)\n# Display the Series\nprint(series_from_list)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.274992Z","iopub.execute_input":"2023-10-25T07:40:52.275619Z","iopub.status.idle":"2023-10-25T07:40:52.285880Z","shell.execute_reply.started":"2023-10-25T07:40:52.275573Z","shell.execute_reply":"2023-10-25T07:40:52.284211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_from_list.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.288055Z","iopub.execute_input":"2023-10-25T07:40:52.288477Z","iopub.status.idle":"2023-10-25T07:40:52.305900Z","shell.execute_reply.started":"2023-10-25T07:40:52.288443Z","shell.execute_reply":"2023-10-25T07:40:52.304371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(series_from_list)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.308542Z","iopub.execute_input":"2023-10-25T07:40:52.309067Z","iopub.status.idle":"2023-10-25T07:40:52.327121Z","shell.execute_reply.started":"2023-10-25T07:40:52.309018Z","shell.execute_reply":"2023-10-25T07:40:52.325535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **2. From a Tuple:**","metadata":{}},{"cell_type":"code","source":"# Create a Pandas Series from a tuple\ndata_tuple = (1, 2, 3, 4, 5)\nseries_from_tuple = pd.Series(data_tuple)\n\n# Display the Series\nprint(series_from_tuple)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.329944Z","iopub.execute_input":"2023-10-25T07:40:52.330407Z","iopub.status.idle":"2023-10-25T07:40:52.343479Z","shell.execute_reply.started":"2023-10-25T07:40:52.330370Z","shell.execute_reply":"2023-10-25T07:40:52.341814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **3. From a Dictionary:**","metadata":{}},{"cell_type":"code","source":"# Create a Pandas Series from a dictionary\ndata_dict = {'A': 10, 'B': 20, 'C': 30, 'D': 40, 'E': 50}\nseries_from_dict = pd.Series(data_dict)\n\n# Display the Series\nprint(series_from_dict)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.345982Z","iopub.execute_input":"2023-10-25T07:40:52.347598Z","iopub.status.idle":"2023-10-25T07:40:52.359621Z","shell.execute_reply.started":"2023-10-25T07:40:52.347533Z","shell.execute_reply":"2023-10-25T07:40:52.358638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **4. From JSON Data (as a string):**","metadata":{}},{"cell_type":"code","source":"# JSON data as a string\njson_data = '{\"A\": 10, \"B\": 20, \"C\": 30, \"D\": 40, \"E\": 50}'\n\n# Create a Pandas Series from JSON data\nseries_from_json = pd.read_json(json_data, typ='series')\n\n# Display the Series\nprint(series_from_json)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.361614Z","iopub.execute_input":"2023-10-25T07:40:52.362226Z","iopub.status.idle":"2023-10-25T07:40:52.379932Z","shell.execute_reply.started":"2023-10-25T07:40:52.362185Z","shell.execute_reply":"2023-10-25T07:40:52.378956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **5. From a String (with data separated by commas):**","metadata":{}},{"cell_type":"code","source":"# Data in CSV format as a string\ncsv_data = \"1,2,3,4,5\"\n\n# Create a Pandas Series from CSV data\nseries_from_csv = pd.Series(csv_data.split(','))\n\n# Display the Series\nprint(series_from_csv)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.382019Z","iopub.execute_input":"2023-10-25T07:40:52.382439Z","iopub.status.idle":"2023-10-25T07:40:52.394265Z","shell.execute_reply.started":"2023-10-25T07:40:52.382404Z","shell.execute_reply":"2023-10-25T07:40:52.392778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **6. From a NumPy Array:**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Create a Pandas Series from a NumPy array\ndata_np = np.array([1, 2, 3, 4, 5])\nseries_from_numpy = pd.Series(data_np)\n\n# Display the Series\nprint(series_from_numpy)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.395813Z","iopub.execute_input":"2023-10-25T07:40:52.396468Z","iopub.status.idle":"2023-10-25T07:40:52.409786Z","shell.execute_reply.started":"2023-10-25T07:40:52.396423Z","shell.execute_reply":"2023-10-25T07:40:52.408479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In each example, a Pandas Series is created from a different data source, and it is then displayed. You can access elements in these Series by index and perform various operations on them, just like you would with any Pandas Series.","metadata":{}},{"cell_type":"markdown","source":"### 2. DataFrame Creation\n\nYou can create a Pandas DataFrame with columns of different data types from various data sources, such as lists, tuples, dictionaries, JSON, strings, and NumPy arrays. Here are examples for each data source:\n\n#### **1. From a List:**","metadata":{}},{"cell_type":"code","source":"data_list = [\n    ['John', 30, 68.5, True, 95.5],\n    ['Alice', 25, 63.2, False, 88.0],\n    ['Bob', 35, 71.0, True, 76.5],\n    ['Eve', 28, 65.8, False, 92.0],\n    ['Charlie', 40, 72.3, False, 87.5]\n]\n\ncolumn_names = ['Name', 'Age', 'Height (inches)', 'Is Student', 'Scores']\n\ndf = pd.DataFrame(data_list, columns=column_names)\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.466875Z","iopub.execute_input":"2023-10-25T07:40:52.467310Z","iopub.status.idle":"2023-10-25T07:40:52.487342Z","shell.execute_reply.started":"2023-10-25T07:40:52.467277Z","shell.execute_reply":"2023-10-25T07:40:52.486031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **2. From a Tuple:**","metadata":{}},{"cell_type":"code","source":"data_tuple = (\n    ('John', 30, 68.5, True, 95.5),\n    ('Alice', 25, 63.2, False, 88.0),\n    ('Bob', 35, 71.0, True, 76.5),\n    ('Eve', 28, 65.8, False, 92.0),\n    ('Charlie', 40, 72.3, False, 87.5)\n)\n\ncolumn_names = ['Name', 'Age', 'Height (inches)', 'Is Student', 'Scores']\n\ndf = pd.DataFrame(data_tuple, columns=column_names)\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.554220Z","iopub.execute_input":"2023-10-25T07:40:52.554672Z","iopub.status.idle":"2023-10-25T07:40:52.573507Z","shell.execute_reply.started":"2023-10-25T07:40:52.554637Z","shell.execute_reply":"2023-10-25T07:40:52.572260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **3. From a Dictionary:**","metadata":{}},{"cell_type":"code","source":"data_dict = {\n    'Name': ['John', 'Alice', 'Bob', 'Eve', 'Charlie'],\n    'Age': [30, 25, 35, 28, 40],\n    'Height (inches)': [68.5, 63.2, 71.0, 65.8, 72.3],\n    'Is Student': [True, False, True, False, False],\n    'Scores': [95.5, 88.0, 76.5, 92.0, 87.5]\n}\n\ndf = pd.DataFrame(data_dict)\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.634306Z","iopub.execute_input":"2023-10-25T07:40:52.634782Z","iopub.status.idle":"2023-10-25T07:40:52.655121Z","shell.execute_reply.started":"2023-10-25T07:40:52.634747Z","shell.execute_reply":"2023-10-25T07:40:52.653409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **4. From JSON Data (as a string):**","metadata":{}},{"cell_type":"code","source":"json_data = '{\"Name\": [\"John\", \"Alice\", \"Bob\", \"Eve\", \"Charlie\"], ' \\\n            '\"Age\": [30, 25, 35, 28, 40], ' \\\n            '\"Height (inches)\": [68.5, 63.2, 71.0, 65.8, 72.3], ' \\\n            '\"Is Student\": [true, false, true, false, false], ' \\\n            '\"Scores\": [95.5, 88.0, 76.5, 92.0, 87.5]}'\n\ndf = pd.read_json(json_data)\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.720596Z","iopub.execute_input":"2023-10-25T07:40:52.721128Z","iopub.status.idle":"2023-10-25T07:40:52.746535Z","shell.execute_reply.started":"2023-10-25T07:40:52.721088Z","shell.execute_reply":"2023-10-25T07:40:52.744978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **5. From a String (with data in CSV or TSV format):**","metadata":{}},{"cell_type":"code","source":"from io import StringIO\ncsv_data = \"\"\"Name, Age, Height (inches), Is Student, Scores\nJohn, 30, 68.5, True, 95.5\nAlice, 25, 63.2, False, 88.0\nBob, 35, 71.0, True, 76.5\nEve, 28, 65.8, False, 92.0\nCharlie, 40, 72.3, False, 87.5\"\"\"\n\ndf = pd.read_csv(StringIO(csv_data))\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.794300Z","iopub.execute_input":"2023-10-25T07:40:52.794734Z","iopub.status.idle":"2023-10-25T07:40:52.813087Z","shell.execute_reply.started":"2023-10-25T07:40:52.794697Z","shell.execute_reply":"2023-10-25T07:40:52.812044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **6. From a NumPy Array:**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndata_np = np.array([\n    ['John', 30, 68.5, True, 95.5],\n    ['Alice', 25, 63.2, False, 88.0],\n    ['Bob', 35, 71.0, True, 76.5],\n    ['Eve', 28, 65.8, False, 92.0],\n    ['Charlie', 40, 72.3, False, 87.5]\n])\n\ncolumn_names = ['Name', 'Age', 'Height (inches)', 'Is Student', 'Scores']\n\ndf = pd.DataFrame(data_np, columns=column_names)\n\n# Convert data types as needed\ndf[['Age', 'Scores']] = df[['Age', 'Scores']].astype(float)\ndf['Is Student'] = df['Is Student'].astype(bool)\n\n# Display the DataFrame\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.864730Z","iopub.execute_input":"2023-10-25T07:40:52.866365Z","iopub.status.idle":"2023-10-25T07:40:52.891213Z","shell.execute_reply.started":"2023-10-25T07:40:52.866311Z","shell.execute_reply":"2023-10-25T07:40:52.889960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These examples demonstrate how to create Pandas DataFrames from various data sources, allowing for columns of different data types. Depending on the data source, you may need to convert data types as necessary to match your desired DataFrame structure.","metadata":{}},{"cell_type":"markdown","source":"# Reading Dataset Files in Pandas","metadata":{}},{"cell_type":"code","source":"# creating different file types dataset from csv\ndf = pd.read_csv(\"/kaggle/input/customer-transactions/sample_dataset.csv\")\ndf = df[:100]\n# # writing dataset to html\ndf.to_html(\"sample_dataset.html\")\n\n# writing dataset as pickle\ndf.to_pickle(\"sample_dataset.pkl\")\n\n# writing dataset as feather\ndf.to_feather(\"sample_dataset.feather\")\n\n# writing dataset as parquet\ndf.to_parquet(\"sample_dataset.parquet\")\n\n# writing dataset as hdf5\ndf.to_hdf(\"sample_dataset.h5\", \"sample_dataset\")\n\n# Save the DataFrame to a tab-separated value (TSV) file\ndf.to_csv('sample_dataset.tsv', sep='\\t', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:52.952031Z","iopub.execute_input":"2023-10-25T07:40:52.953134Z","iopub.status.idle":"2023-10-25T07:40:53.155834Z","shell.execute_reply.started":"2023-10-25T07:40:52.953075Z","shell.execute_reply":"2023-10-25T07:40:53.154536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pandas is a versatile library that allows you to read various types of files into a DataFrame. Here's how you can read different types of files using Pandas:\n\n#### 1. **CSV Files:**\n   To read a CSV file, you can use the `pd.read_csv()` function:\n   ```python\n   import pandas as pd\n   df = pd.read_csv('your_file.csv')\n   ```","metadata":{}},{"cell_type":"code","source":"csv_df = pd.read_csv('/kaggle/input/customer-transactions/sample_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.157972Z","iopub.execute_input":"2023-10-25T07:40:53.158365Z","iopub.status.idle":"2023-10-25T07:40:53.287790Z","shell.execute_reply.started":"2023-10-25T07:40:53.158331Z","shell.execute_reply":"2023-10-25T07:40:53.286524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.289660Z","iopub.execute_input":"2023-10-25T07:40:53.290069Z","iopub.status.idle":"2023-10-25T07:40:53.297674Z","shell.execute_reply.started":"2023-10-25T07:40:53.290034Z","shell.execute_reply":"2023-10-25T07:40:53.296399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.300949Z","iopub.execute_input":"2023-10-25T07:40:53.301448Z","iopub.status.idle":"2023-10-25T07:40:53.322017Z","shell.execute_reply.started":"2023-10-25T07:40:53.301413Z","shell.execute_reply":"2023-10-25T07:40:53.320761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. **Excel Files:**\n   To read an Excel file, use the `pd.read_excel()` function:\n   ```python\n   import pandas as pd\n   df = pd.read_excel('your_file.xlsx')\n   ```","metadata":{}},{"cell_type":"code","source":"excel_df = pd.read_excel('/kaggle/input/dirty-excel-data/Cola.xlsx')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.324097Z","iopub.execute_input":"2023-10-25T07:40:53.324601Z","iopub.status.idle":"2023-10-25T07:40:53.390399Z","shell.execute_reply.started":"2023-10-25T07:40:53.324565Z","shell.execute_reply":"2023-10-25T07:40:53.388972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.391594Z","iopub.execute_input":"2023-10-25T07:40:53.391988Z","iopub.status.idle":"2023-10-25T07:40:53.400284Z","shell.execute_reply.started":"2023-10-25T07:40:53.391908Z","shell.execute_reply":"2023-10-25T07:40:53.398936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.402300Z","iopub.execute_input":"2023-10-25T07:40:53.402788Z","iopub.status.idle":"2023-10-25T07:40:53.426752Z","shell.execute_reply.started":"2023-10-25T07:40:53.402745Z","shell.execute_reply":"2023-10-25T07:40:53.425672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. **SQL Databases:**\n   You can use the `pandas.read_sql()` function to read data from a SQL database using an appropriate connection:\n   ```python\n   import pandas as pd\n   import sqlite3  # Example using SQLite\n   conn = sqlite3.connect('your_database.db')\n   query = 'SELECT * FROM your_table'\n   df = pd.read_sql(query, conn)\n   ```","metadata":{}},{"cell_type":"code","source":"import sqlite3\n\n# Create a connection to the SQLite database\nconn = sqlite3.connect('/kaggle/input/imdb-project-sql/movies.sqlite')\n\n# Create a cursor object\ncursor = conn.cursor()\n\n# Execute a query to fetch table names from the 'sqlite_master' table\ncursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n\n# Fetch all the table names\ntable_names = cursor.fetchall()\n\n# Close the database connection\nconn.close()\n\n# Extract table names from the result\ntable_names = [table[0] for table in table_names]\n\n# Print the table names\nfor table_name in table_names:\n    print(table_name)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.429263Z","iopub.execute_input":"2023-10-25T07:40:53.429912Z","iopub.status.idle":"2023-10-25T07:40:53.459322Z","shell.execute_reply.started":"2023-10-25T07:40:53.429862Z","shell.execute_reply":"2023-10-25T07:40:53.458275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conn = sqlite3.connect('/kaggle/input/imdb-project-sql/movies.sqlite')\nquery = 'SELECT * FROM movies'\nsql_df = pd.read_sql(query, conn)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:53.460347Z","iopub.execute_input":"2023-10-25T07:40:53.460673Z","iopub.status.idle":"2023-10-25T07:40:54.016844Z","shell.execute_reply.started":"2023-10-25T07:40:53.460644Z","shell.execute_reply":"2023-10-25T07:40:54.015861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sql_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.021154Z","iopub.execute_input":"2023-10-25T07:40:54.022254Z","iopub.status.idle":"2023-10-25T07:40:54.029126Z","shell.execute_reply.started":"2023-10-25T07:40:54.022214Z","shell.execute_reply":"2023-10-25T07:40:54.028001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sql_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.031020Z","iopub.execute_input":"2023-10-25T07:40:54.031651Z","iopub.status.idle":"2023-10-25T07:40:54.056490Z","shell.execute_reply.started":"2023-10-25T07:40:54.031615Z","shell.execute_reply":"2023-10-25T07:40:54.055263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 4. **JSON Files:**\n   To read JSON data, use the `pd.read_json()` function:\n   ```python\n   import pandas as pd\n   df = pd.read_json('your_file.json')\n   ```","metadata":{}},{"cell_type":"code","source":"json_df = pd.read_json('/kaggle/input/iris-dataset-json-version/iris.json')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.057993Z","iopub.execute_input":"2023-10-25T07:40:54.059041Z","iopub.status.idle":"2023-10-25T07:40:54.072791Z","shell.execute_reply.started":"2023-10-25T07:40:54.059002Z","shell.execute_reply":"2023-10-25T07:40:54.071604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.074301Z","iopub.execute_input":"2023-10-25T07:40:54.074888Z","iopub.status.idle":"2023-10-25T07:40:54.081725Z","shell.execute_reply.started":"2023-10-25T07:40:54.074854Z","shell.execute_reply":"2023-10-25T07:40:54.080489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.083284Z","iopub.execute_input":"2023-10-25T07:40:54.083659Z","iopub.status.idle":"2023-10-25T07:40:54.104736Z","shell.execute_reply.started":"2023-10-25T07:40:54.083625Z","shell.execute_reply":"2023-10-25T07:40:54.103594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. **HTML Tables:**\n   You can scrape tables from HTML web pages using `pd.read_html()`. This function returns a list of DataFrames if there are multiple tables on the page:\n   ```python\n   import pandas as pd\n   dfs = pd.read_html('https://example.com/page_with_tables.html')\n   df = dfs[0]  # Select the appropriate DataFrame from the list\n   ```\n   \n   ","metadata":{}},{"cell_type":"code","source":"html_df = pd.read_html(\"/kaggle/working/sample_dataset.html\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.106801Z","iopub.execute_input":"2023-10-25T07:40:54.107442Z","iopub.status.idle":"2023-10-25T07:40:54.141748Z","shell.execute_reply.started":"2023-10-25T07:40:54.107397Z","shell.execute_reply":"2023-10-25T07:40:54.140491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"html_df = html_df[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.143766Z","iopub.execute_input":"2023-10-25T07:40:54.144176Z","iopub.status.idle":"2023-10-25T07:40:54.150936Z","shell.execute_reply.started":"2023-10-25T07:40:54.144142Z","shell.execute_reply":"2023-10-25T07:40:54.149345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"html_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.152439Z","iopub.execute_input":"2023-10-25T07:40:54.152841Z","iopub.status.idle":"2023-10-25T07:40:54.167290Z","shell.execute_reply.started":"2023-10-25T07:40:54.152806Z","shell.execute_reply":"2023-10-25T07:40:54.166036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"html_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.169333Z","iopub.execute_input":"2023-10-25T07:40:54.170453Z","iopub.status.idle":"2023-10-25T07:40:54.194763Z","shell.execute_reply.started":"2023-10-25T07:40:54.170411Z","shell.execute_reply":"2023-10-25T07:40:54.193321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. **Clipboard Content:**\n   You can read data from your clipboard using `pd.read_clipboard()`:\n   ```python\n   import pandas as pd\n   df = pd.read_clipboard()\n   ```","metadata":{}},{"cell_type":"markdown","source":"#### 7. **Other Text-Based Formats:**\n   Pandas can read other text-based formats like TSV (Tab-Separated Values) or any delimited text files using `pd.read_csv()` by specifying the delimiter:\n   ```python\n   import pandas as pd\n   df = pd.read_csv('your_file.tsv', delimiter='\\t')\n   ```","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/working/sample_dataset.tsv\",sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.196042Z","iopub.execute_input":"2023-10-25T07:40:54.196437Z","iopub.status.idle":"2023-10-25T07:40:54.230549Z","shell.execute_reply.started":"2023-10-25T07:40:54.196403Z","shell.execute_reply":"2023-10-25T07:40:54.229496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8. **Parquet Files:**\n   To read Parquet files, you can use the `pd.read_parquet()` function:\n   ```python\n   import pandas as pd\n   df = pd.read_parquet('your_file.parquet')\n   ```","metadata":{}},{"cell_type":"code","source":"pd.read_parquet(\"/kaggle/working/sample_dataset.parquet\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.232074Z","iopub.execute_input":"2023-10-25T07:40:54.233179Z","iopub.status.idle":"2023-10-25T07:40:54.261395Z","shell.execute_reply.started":"2023-10-25T07:40:54.233139Z","shell.execute_reply":"2023-10-25T07:40:54.260201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9. **HDF5 Files:**\n   Pandas can read data from HDF5 files using the `pd.read_hdf()` function:\n   ```python\n   import pandas as pd\n   df = pd.read_hdf('your_file.h5')\n   ```","metadata":{}},{"cell_type":"code","source":"pd.read_hdf(\"/kaggle/working/sample_dataset.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.263344Z","iopub.execute_input":"2023-10-25T07:40:54.263746Z","iopub.status.idle":"2023-10-25T07:40:54.304007Z","shell.execute_reply.started":"2023-10-25T07:40:54.263709Z","shell.execute_reply":"2023-10-25T07:40:54.302690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 10. **Feather Files:**\n    Feather is another file format for efficiently storing data frames. You can use `pd.read_feather()` to read Feather files:\n    ```python\n    import pandas as pd\n    df = pd.read_feather('your_file.feather')\n    ```","metadata":{}},{"cell_type":"code","source":"pd.read_feather('/kaggle/working/sample_dataset.feather')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.305665Z","iopub.execute_input":"2023-10-25T07:40:54.306154Z","iopub.status.idle":"2023-10-25T07:40:54.334476Z","shell.execute_reply.started":"2023-10-25T07:40:54.306112Z","shell.execute_reply":"2023-10-25T07:40:54.333184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are some common file formats that Pandas can handle. Depending on your data source and format, you can choose the appropriate function to read the data into a Pandas DataFrame.","metadata":{}},{"cell_type":"markdown","source":"# Data Exploration and Information:\nData exploration and information functions in Pandas are used to gain insights into your data, understand its structure, and obtain summary statistics. Here are some common data exploration and information functions in Pandas:\n\n1. **`head(n)` and `tail(n)`**:\n   - `df.head(n)`: Returns the first `n` rows of the DataFrame (default is 5).\n   - `df.tail(n)`: Returns the last `n` rows of the DataFrame (default is 5).\n\n2. **`info()`**:\n   - `df.info()`: Provides a summary of the DataFrame, including the data types of columns and the count of non-null values. Useful for understanding the data's structure.\n\n3. **`describe()`**:\n   - `df.describe()`: Generates descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max) for numerical columns.\n\n4. **`shape`**:\n   - `df.shape`: Returns a tuple representing the dimensions of the DataFrame (number of rows, number of columns).\n\n5. **`dtypes`**:\n   - `df.dtypes`: Returns a Series with the data types of each column.\n\n6. **`columns`**:\n   - `df.columns`: Returns a list of column names.\n\n7. **`nunique()` and `unique()`**:\n   - `df['column_name'].nunique()`: Returns the number of unique values in a specific column.\n   - `df['column_name'].unique()`: Returns an array of unique values in a specific column.\n\n8. **`value_counts()`**:\n   - `df['column_name'].value_counts()`: Counts the frequency of each unique value in a specific column.\n\n9. **`isna()` and `isnull()`**:\n   - `df.isna()`: Returns a DataFrame of the same shape with `True` for missing values and `False` for non-missing values.\n   - `df.isnull()`: Same as `isna()`.\n\n10. **`notna()` and `notnull()`**:\n   - `df.notna()`: Returns a DataFrame of the same shape with `True` for non-missing values and `False` for missing values.\n   - `df.notnull()`: Same as `notna()`.\n\n11. **`corr()`**:\n   - `df.corr()`: Calculates the pairwise correlation of numerical columns in the DataFrame.\n\n12. **`cov()`**:\n   - `df.cov()`: Calculates the covariance matrix of numerical columns.\n\n13. **`mean()`, `median()`, `std()`, `min()`, and `max()`**:\n   - `df.mean()`: Computes the mean of each numerical column.\n   - `df.median()`: Computes the median of each numerical column.\n   - `df.std()`: Computes the standard deviation of each numerical column.\n   - `df.min()`: Returns the minimum value of each column.\n   - `df.max()`: Returns the maximum value of each column.\n\nThese functions are valuable for understanding your data, identifying missing values, finding summary statistics, and performing initial data exploration and cleaning before more in-depth analysis.","metadata":{}},{"cell_type":"code","source":"df = pd.read_feather('/kaggle/working/sample_dataset.feather')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.336477Z","iopub.execute_input":"2023-10-25T07:40:54.336852Z","iopub.status.idle":"2023-10-25T07:40:54.349605Z","shell.execute_reply.started":"2023-10-25T07:40:54.336822Z","shell.execute_reply":"2023-10-25T07:40:54.348310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shape of data\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.351409Z","iopub.execute_input":"2023-10-25T07:40:54.352344Z","iopub.status.idle":"2023-10-25T07:40:54.359501Z","shell.execute_reply.started":"2023-10-25T07:40:54.352306Z","shell.execute_reply":"2023-10-25T07:40:54.358154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# view the table - first 5 data\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.361069Z","iopub.execute_input":"2023-10-25T07:40:54.361462Z","iopub.status.idle":"2023-10-25T07:40:54.385963Z","shell.execute_reply.started":"2023-10-25T07:40:54.361427Z","shell.execute_reply":"2023-10-25T07:40:54.384501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# last 5 data\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.387759Z","iopub.execute_input":"2023-10-25T07:40:54.388189Z","iopub.status.idle":"2023-10-25T07:40:54.410888Z","shell.execute_reply.started":"2023-10-25T07:40:54.388152Z","shell.execute_reply":"2023-10-25T07:40:54.409563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# random 5 sample\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.417628Z","iopub.execute_input":"2023-10-25T07:40:54.418322Z","iopub.status.idle":"2023-10-25T07:40:54.439219Z","shell.execute_reply.started":"2023-10-25T07:40:54.418265Z","shell.execute_reply":"2023-10-25T07:40:54.438272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# viewing data info\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.440581Z","iopub.execute_input":"2023-10-25T07:40:54.440993Z","iopub.status.idle":"2023-10-25T07:40:54.456001Z","shell.execute_reply.started":"2023-10-25T07:40:54.440955Z","shell.execute_reply":"2023-10-25T07:40:54.454336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data\ndf.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.457873Z","iopub.execute_input":"2023-10-25T07:40:54.458364Z","iopub.status.idle":"2023-10-25T07:40:54.483637Z","shell.execute_reply.started":"2023-10-25T07:40:54.458329Z","shell.execute_reply":"2023-10-25T07:40:54.482742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.485084Z","iopub.execute_input":"2023-10-25T07:40:54.485446Z","iopub.status.idle":"2023-10-25T07:40:54.494313Z","shell.execute_reply.started":"2023-10-25T07:40:54.485413Z","shell.execute_reply":"2023-10-25T07:40:54.493015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.495605Z","iopub.execute_input":"2023-10-25T07:40:54.496842Z","iopub.status.idle":"2023-10-25T07:40:54.511249Z","shell.execute_reply.started":"2023-10-25T07:40:54.496804Z","shell.execute_reply":"2023-10-25T07:40:54.509748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.512696Z","iopub.execute_input":"2023-10-25T07:40:54.513082Z","iopub.status.idle":"2023-10-25T07:40:54.532500Z","shell.execute_reply.started":"2023-10-25T07:40:54.513045Z","shell.execute_reply":"2023-10-25T07:40:54.531030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Gender'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.534185Z","iopub.execute_input":"2023-10-25T07:40:54.534588Z","iopub.status.idle":"2023-10-25T07:40:54.546811Z","shell.execute_reply.started":"2023-10-25T07:40:54.534554Z","shell.execute_reply":"2023-10-25T07:40:54.545914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Category'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.548175Z","iopub.execute_input":"2023-10-25T07:40:54.549150Z","iopub.status.idle":"2023-10-25T07:40:54.562312Z","shell.execute_reply.started":"2023-10-25T07:40:54.549114Z","shell.execute_reply":"2023-10-25T07:40:54.559811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Gender'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.563937Z","iopub.execute_input":"2023-10-25T07:40:54.564513Z","iopub.status.idle":"2023-10-25T07:40:54.577133Z","shell.execute_reply.started":"2023-10-25T07:40:54.564479Z","shell.execute_reply":"2023-10-25T07:40:54.576215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Category'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.578483Z","iopub.execute_input":"2023-10-25T07:40:54.579505Z","iopub.status.idle":"2023-10-25T07:40:54.594607Z","shell.execute_reply.started":"2023-10-25T07:40:54.579405Z","shell.execute_reply":"2023-10-25T07:40:54.592759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Gender'].value_counts(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.596423Z","iopub.execute_input":"2023-10-25T07:40:54.597492Z","iopub.status.idle":"2023-10-25T07:40:54.608894Z","shell.execute_reply.started":"2023-10-25T07:40:54.597449Z","shell.execute_reply":"2023-10-25T07:40:54.607947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Category'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.610239Z","iopub.execute_input":"2023-10-25T07:40:54.610770Z","iopub.status.idle":"2023-10-25T07:40:54.624391Z","shell.execute_reply.started":"2023-10-25T07:40:54.610736Z","shell.execute_reply":"2023-10-25T07:40:54.623566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.625674Z","iopub.execute_input":"2023-10-25T07:40:54.626220Z","iopub.status.idle":"2023-10-25T07:40:54.639407Z","shell.execute_reply.started":"2023-10-25T07:40:54.626188Z","shell.execute_reply":"2023-10-25T07:40:54.638448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df[df.notna().all(axis=1)]\ndf.notna().all()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.640970Z","iopub.execute_input":"2023-10-25T07:40:54.641537Z","iopub.status.idle":"2023-10-25T07:40:54.655115Z","shell.execute_reply.started":"2023-10-25T07:40:54.641505Z","shell.execute_reply":"2023-10-25T07:40:54.653807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# discard all none/null rows\ndf[df.notna().all(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.657131Z","iopub.execute_input":"2023-10-25T07:40:54.657707Z","iopub.status.idle":"2023-10-25T07:40:54.680559Z","shell.execute_reply.started":"2023-10-25T07:40:54.657658Z","shell.execute_reply":"2023-10-25T07:40:54.679708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.681981Z","iopub.execute_input":"2023-10-25T07:40:54.682505Z","iopub.status.idle":"2023-10-25T07:40:54.691665Z","shell.execute_reply.started":"2023-10-25T07:40:54.682473Z","shell.execute_reply":"2023-10-25T07:40:54.690304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['Gender'].isna()]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.698261Z","iopub.execute_input":"2023-10-25T07:40:54.698664Z","iopub.status.idle":"2023-10-25T07:40:54.719444Z","shell.execute_reply.started":"2023-10-25T07:40:54.698633Z","shell.execute_reply":"2023-10-25T07:40:54.718193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract all records of none value in gender\ndf[df['Gender'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.721109Z","iopub.execute_input":"2023-10-25T07:40:54.721452Z","iopub.status.idle":"2023-10-25T07:40:54.742855Z","shell.execute_reply.started":"2023-10-25T07:40:54.721423Z","shell.execute_reply":"2023-10-25T07:40:54.741663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract df where no null values in gender columns, other columns might have null values\ndf[df['Gender'].notna()]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.744558Z","iopub.execute_input":"2023-10-25T07:40:54.745068Z","iopub.status.idle":"2023-10-25T07:40:54.769732Z","shell.execute_reply.started":"2023-10-25T07:40:54.745032Z","shell.execute_reply":"2023-10-25T07:40:54.768793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = excel_df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.771083Z","iopub.execute_input":"2023-10-25T07:40:54.772140Z","iopub.status.idle":"2023-10-25T07:40:54.783679Z","shell.execute_reply.started":"2023-10-25T07:40:54.772097Z","shell.execute_reply":"2023-10-25T07:40:54.782124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.784988Z","iopub.execute_input":"2023-10-25T07:40:54.786570Z","iopub.status.idle":"2023-10-25T07:40:54.811174Z","shell.execute_reply.started":"2023-10-25T07:40:54.786525Z","shell.execute_reply":"2023-10-25T07:40:54.809830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic = {}\nfor i in range(12):\n    dic[f'Unnamed: {i}'] = f'Col{i}'","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.812697Z","iopub.execute_input":"2023-10-25T07:40:54.813485Z","iopub.status.idle":"2023-10-25T07:40:54.825254Z","shell.execute_reply.started":"2023-10-25T07:40:54.813449Z","shell.execute_reply":"2023-10-25T07:40:54.823675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.827121Z","iopub.execute_input":"2023-10-25T07:40:54.827527Z","iopub.status.idle":"2023-10-25T07:40:54.842940Z","shell.execute_reply.started":"2023-10-25T07:40:54.827493Z","shell.execute_reply":"2023-10-25T07:40:54.842023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = {'Data provided by SimFin':'Data',\n 'Unnamed: 0': 'Col0',\n 'Unnamed: 1': 'Col1',\n 'Unnamed: 2': 'Col2',\n 'Unnamed: 3': 'Col3',\n 'Unnamed: 4': 'Col4',\n 'Unnamed: 5': 'Col5',\n 'Unnamed: 6': 'Col6',\n 'Unnamed: 7': 'Col7',\n 'Unnamed: 8': 'Col8',\n 'Unnamed: 9': 'Col9',\n 'Unnamed: 10': 'Col10',\n 'Unnamed: 11': 'Col11'}","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.844257Z","iopub.execute_input":"2023-10-25T07:40:54.844629Z","iopub.status.idle":"2023-10-25T07:40:54.858893Z","shell.execute_reply.started":"2023-10-25T07:40:54.844596Z","shell.execute_reply":"2023-10-25T07:40:54.857800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.rename(columns=columns, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.860644Z","iopub.execute_input":"2023-10-25T07:40:54.861049Z","iopub.status.idle":"2023-10-25T07:40:54.875464Z","shell.execute_reply.started":"2023-10-25T07:40:54.861014Z","shell.execute_reply":"2023-10-25T07:40:54.874072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.877296Z","iopub.execute_input":"2023-10-25T07:40:54.877881Z","iopub.status.idle":"2023-10-25T07:40:54.900590Z","shell.execute_reply.started":"2023-10-25T07:40:54.877846Z","shell.execute_reply":"2023-10-25T07:40:54.899299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.902370Z","iopub.execute_input":"2023-10-25T07:40:54.902759Z","iopub.status.idle":"2023-10-25T07:40:54.923709Z","shell.execute_reply.started":"2023-10-25T07:40:54.902721Z","shell.execute_reply":"2023-10-25T07:40:54.921843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.925891Z","iopub.execute_input":"2023-10-25T07:40:54.926600Z","iopub.status.idle":"2023-10-25T07:40:54.941435Z","shell.execute_reply.started":"2023-10-25T07:40:54.926562Z","shell.execute_reply":"2023-10-25T07:40:54.940245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.notna().all()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.943284Z","iopub.execute_input":"2023-10-25T07:40:54.944385Z","iopub.status.idle":"2023-10-25T07:40:54.956139Z","shell.execute_reply.started":"2023-10-25T07:40:54.944335Z","shell.execute_reply":"2023-10-25T07:40:54.955059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.957678Z","iopub.execute_input":"2023-10-25T07:40:54.958494Z","iopub.status.idle":"2023-10-25T07:40:54.969796Z","shell.execute_reply.started":"2023-10-25T07:40:54.958455Z","shell.execute_reply":"2023-10-25T07:40:54.968521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.971449Z","iopub.execute_input":"2023-10-25T07:40:54.972025Z","iopub.status.idle":"2023-10-25T07:40:54.986699Z","shell.execute_reply.started":"2023-10-25T07:40:54.971987Z","shell.execute_reply":"2023-10-25T07:40:54.985858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:54.987836Z","iopub.execute_input":"2023-10-25T07:40:54.988777Z","iopub.status.idle":"2023-10-25T07:40:55.004721Z","shell.execute_reply.started":"2023-10-25T07:40:54.988740Z","shell.execute_reply":"2023-10-25T07:40:55.003816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.012854Z","iopub.execute_input":"2023-10-25T07:40:55.013788Z","iopub.status.idle":"2023-10-25T07:40:55.062809Z","shell.execute_reply.started":"2023-10-25T07:40:55.013746Z","shell.execute_reply":"2023-10-25T07:40:55.061478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Indexing, Slicing and Selection\n\nIndexing, slicing, and selection in Pandas are essential techniques for extracting and manipulating data from DataFrames and Series. They allow you to access specific rows and columns or subsets of your data. Here's a detailed explanation of how these operations work in Pandas:\n\n1. **Indexing DataFrames**:\n\n   - **By Column Name**:\n     - To access a specific column, use `df['column_name']`. This returns a Series.\n     - Example: `df['Age']`.\n\n   - **By Attribute**:\n     - If column names are valid Python variable names, you can access columns using attributes, like `df.column_name`.\n     - Example: `df.Age`.\n\n   - **By Column Index**:\n     - You can access a column by its position (index) using `df.iloc[:, col_index]`.\n     - Example: `df.iloc[:, 1]` to access the second column.\n\n2. **Slicing DataFrames**:\n\n   - **Slicing Rows**:\n     - To select a range of rows, use `df[start_row:end_row]`. The end row is exclusive.\n     - Example: `df[1:4]` returns rows 2 to 4.\n\n   - **Slicing Columns**:\n     - To select a subset of columns, use `df[['col1', 'col2']]` to select specific columns.\n     - Example: `df[['Name', 'Age']]`.\n\n3. **Selection by Label**:\n\n   - **`.loc[]`**:\n     - Use `.loc[]` to select data by label. You can specify rows and columns by their labels.\n     - Example: `df.loc[1:4, 'Name':'Age']` selects rows 2 to 4 and columns 'Name' to 'Age'.\n\n4. **Selection by Position**:\n\n   - **`.iloc[]`**:\n     - Use `.iloc[]` to select data by integer position. You can specify rows and columns by their position.\n     - Example: `df.iloc[1:4, 0:2]` selects rows 2 to 4 and the first two columns.\n\n5. **Boolean Indexing**:\n\n   - You can create Boolean masks to filter rows based on a condition. For example, `df[df['Age'] > 30]` selects rows where 'Age' is greater than 30.\n\n6. **Combining Selections**:\n\n   - You can combine selections for complex data extraction.\n   - Example: `df.loc[df['Age'] > 30, ['Name', 'Age']]` selects the 'Name' and 'Age' columns for rows where 'Age' is greater than 30.\n\n7. **`.at[]` and `.iat[]`**:\n\n   - These methods provide faster access to single elements by label or position, respectively.\n   - Example: `df.at[2, 'Age']` returns the value at row 3 and the 'Age' column.\n\n8. **Chained Indexing**:\n\n   - Avoid using chained indexing, like `df[1:3]['Name']`. Use `.loc[]` or `.iloc[]` for better performance and to avoid setting with copy errors.\n\nPandas provides a wide range of indexing and selection methods to make it convenient to access and manipulate data. Understanding these techniques is crucial for effective data analysis and manipulation.","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/sales-and-customer-data/customer_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.064589Z","iopub.execute_input":"2023-10-25T07:40:55.065313Z","iopub.status.idle":"2023-10-25T07:40:55.184248Z","shell.execute_reply.started":"2023-10-25T07:40:55.065243Z","shell.execute_reply":"2023-10-25T07:40:55.183339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['customer_id']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.185588Z","iopub.execute_input":"2023-10-25T07:40:55.186662Z","iopub.status.idle":"2023-10-25T07:40:55.199227Z","shell.execute_reply.started":"2023-10-25T07:40:55.186615Z","shell.execute_reply":"2023-10-25T07:40:55.197658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.customer_id","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.201488Z","iopub.execute_input":"2023-10-25T07:40:55.202012Z","iopub.status.idle":"2023-10-25T07:40:55.215483Z","shell.execute_reply.started":"2023-10-25T07:40:55.201959Z","shell.execute_reply":"2023-10-25T07:40:55.214201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,1]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.216829Z","iopub.execute_input":"2023-10-25T07:40:55.217185Z","iopub.status.idle":"2023-10-25T07:40:55.233437Z","shell.execute_reply.started":"2023-10-25T07:40:55.217155Z","shell.execute_reply":"2023-10-25T07:40:55.231931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,[1,3]]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.235145Z","iopub.execute_input":"2023-10-25T07:40:55.235539Z","iopub.status.idle":"2023-10-25T07:40:55.257776Z","shell.execute_reply.started":"2023-10-25T07:40:55.235506Z","shell.execute_reply":"2023-10-25T07:40:55.256522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,:2]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.259668Z","iopub.execute_input":"2023-10-25T07:40:55.260180Z","iopub.status.idle":"2023-10-25T07:40:55.282348Z","shell.execute_reply.started":"2023-10-25T07:40:55.260121Z","shell.execute_reply":"2023-10-25T07:40:55.281296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[:,::-1]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.283549Z","iopub.execute_input":"2023-10-25T07:40:55.284550Z","iopub.status.idle":"2023-10-25T07:40:55.308505Z","shell.execute_reply.started":"2023-10-25T07:40:55.284511Z","shell.execute_reply":"2023-10-25T07:40:55.307007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.310464Z","iopub.execute_input":"2023-10-25T07:40:55.310837Z","iopub.status.idle":"2023-10-25T07:40:55.332334Z","shell.execute_reply.started":"2023-10-25T07:40:55.310806Z","shell.execute_reply":"2023-10-25T07:40:55.330862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.334258Z","iopub.execute_input":"2023-10-25T07:40:55.334648Z","iopub.status.idle":"2023-10-25T07:40:55.355893Z","shell.execute_reply.started":"2023-10-25T07:40:55.334616Z","shell.execute_reply":"2023-10-25T07:40:55.354251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[5:10]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.362705Z","iopub.execute_input":"2023-10-25T07:40:55.363185Z","iopub.status.idle":"2023-10-25T07:40:55.379801Z","shell.execute_reply.started":"2023-10-25T07:40:55.363149Z","shell.execute_reply":"2023-10-25T07:40:55.378388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['age']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.381657Z","iopub.execute_input":"2023-10-25T07:40:55.382172Z","iopub.status.idle":"2023-10-25T07:40:55.397119Z","shell.execute_reply.started":"2023-10-25T07:40:55.382127Z","shell.execute_reply":"2023-10-25T07:40:55.395959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['gender','age']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.399483Z","iopub.execute_input":"2023-10-25T07:40:55.400421Z","iopub.status.idle":"2023-10-25T07:40:55.418844Z","shell.execute_reply.started":"2023-10-25T07:40:55.400371Z","shell.execute_reply":"2023-10-25T07:40:55.417480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['gender','age','payment_method']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.421428Z","iopub.execute_input":"2023-10-25T07:40:55.422168Z","iopub.status.idle":"2023-10-25T07:40:55.456972Z","shell.execute_reply.started":"2023-10-25T07:40:55.422121Z","shell.execute_reply":"2023-10-25T07:40:55.455519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create a label index dataframe\nimport pandas as pd\nimport random\nimport string\n\nstudents = student_names = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eva\", \"Frank\", \"Grace\", \"Henry\", \"Ivy\", \"Jack\"]\n\n# Create a random marks DataFrame\nsubjects = ['Math', 'Science', 'History', 'English', 'Art']\ndata = {subject: [random.randint(50, 100) for _ in range(10)] for subject in subjects}\ndummy = pd.DataFrame(data, index=students)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.460292Z","iopub.execute_input":"2023-10-25T07:40:55.461138Z","iopub.status.idle":"2023-10-25T07:40:55.470733Z","shell.execute_reply.started":"2023-10-25T07:40:55.461090Z","shell.execute_reply":"2023-10-25T07:40:55.469158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the DataFrame\ndummy","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.474390Z","iopub.execute_input":"2023-10-25T07:40:55.475441Z","iopub.status.idle":"2023-10-25T07:40:55.492389Z","shell.execute_reply.started":"2023-10-25T07:40:55.475396Z","shell.execute_reply":"2023-10-25T07:40:55.491475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.loc['Alice']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.493664Z","iopub.execute_input":"2023-10-25T07:40:55.494630Z","iopub.status.idle":"2023-10-25T07:40:55.509994Z","shell.execute_reply.started":"2023-10-25T07:40:55.494592Z","shell.execute_reply":"2023-10-25T07:40:55.508478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.loc[[\"Alice\",\"Ivy\"]] # two rows by their index name","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.511284Z","iopub.execute_input":"2023-10-25T07:40:55.512456Z","iopub.status.idle":"2023-10-25T07:40:55.532048Z","shell.execute_reply.started":"2023-10-25T07:40:55.512418Z","shell.execute_reply":"2023-10-25T07:40:55.530703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.loc[['Eva','Frank'],['Math',\"Science\",'English']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.533999Z","iopub.execute_input":"2023-10-25T07:40:55.534666Z","iopub.status.idle":"2023-10-25T07:40:55.559260Z","shell.execute_reply.started":"2023-10-25T07:40:55.534625Z","shell.execute_reply":"2023-10-25T07:40:55.557943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.loc[:,:]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.560638Z","iopub.execute_input":"2023-10-25T07:40:55.561186Z","iopub.status.idle":"2023-10-25T07:40:55.574678Z","shell.execute_reply.started":"2023-10-25T07:40:55.561151Z","shell.execute_reply":"2023-10-25T07:40:55.573434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.loc[:,[\"English\",\"Math\",'Science']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.580152Z","iopub.execute_input":"2023-10-25T07:40:55.580664Z","iopub.status.idle":"2023-10-25T07:40:55.596682Z","shell.execute_reply.started":"2023-10-25T07:40:55.580623Z","shell.execute_reply":"2023-10-25T07:40:55.594816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy[dummy['Math']>60].sort_values(\"Math\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.598817Z","iopub.execute_input":"2023-10-25T07:40:55.599692Z","iopub.status.idle":"2023-10-25T07:40:55.621393Z","shell.execute_reply.started":"2023-10-25T07:40:55.599563Z","shell.execute_reply":"2023-10-25T07:40:55.620071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy[dummy['Math']>60].sort_values(\"Math\")[['Math','Science','Art']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.623336Z","iopub.execute_input":"2023-10-25T07:40:55.624133Z","iopub.status.idle":"2023-10-25T07:40:55.639424Z","shell.execute_reply.started":"2023-10-25T07:40:55.624086Z","shell.execute_reply":"2023-10-25T07:40:55.638005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[:5,\"age\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.641411Z","iopub.execute_input":"2023-10-25T07:40:55.642332Z","iopub.status.idle":"2023-10-25T07:40:55.659367Z","shell.execute_reply.started":"2023-10-25T07:40:55.642287Z","shell.execute_reply":"2023-10-25T07:40:55.657835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df.age>30][['gender','age']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.661188Z","iopub.execute_input":"2023-10-25T07:40:55.662022Z","iopub.status.idle":"2023-10-25T07:40:55.692319Z","shell.execute_reply.started":"2023-10-25T07:40:55.661973Z","shell.execute_reply":"2023-10-25T07:40:55.691091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df['age'] > 30, ['gender', 'age']][:2]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.693987Z","iopub.execute_input":"2023-10-25T07:40:55.695213Z","iopub.status.idle":"2023-10-25T07:40:55.716495Z","shell.execute_reply.started":"2023-10-25T07:40:55.695173Z","shell.execute_reply":"2023-10-25T07:40:55.715411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[df['age']<20,['age','gender']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.721015Z","iopub.execute_input":"2023-10-25T07:40:55.721432Z","iopub.status.idle":"2023-10-25T07:40:55.741402Z","shell.execute_reply.started":"2023-10-25T07:40:55.721401Z","shell.execute_reply":"2023-10-25T07:40:55.740442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['age']==20]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.743238Z","iopub.execute_input":"2023-10-25T07:40:55.743728Z","iopub.status.idle":"2023-10-25T07:40:55.764254Z","shell.execute_reply.started":"2023-10-25T07:40:55.743684Z","shell.execute_reply":"2023-10-25T07:40:55.763015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[:5]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.766095Z","iopub.execute_input":"2023-10-25T07:40:55.767385Z","iopub.status.idle":"2023-10-25T07:40:55.781168Z","shell.execute_reply.started":"2023-10-25T07:40:55.767337Z","shell.execute_reply":"2023-10-25T07:40:55.779694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.at[0,'age'] # age value at index row 0","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.782936Z","iopub.execute_input":"2023-10-25T07:40:55.783433Z","iopub.status.idle":"2023-10-25T07:40:55.797447Z","shell.execute_reply.started":"2023-10-25T07:40:55.783387Z","shell.execute_reply":"2023-10-25T07:40:55.796463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.at[2,'gender'] ","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.799861Z","iopub.execute_input":"2023-10-25T07:40:55.800428Z","iopub.status.idle":"2023-10-25T07:40:55.822188Z","shell.execute_reply.started":"2023-10-25T07:40:55.800382Z","shell.execute_reply":"2023-10-25T07:40:55.820479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iat[0,2]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.824054Z","iopub.execute_input":"2023-10-25T07:40:55.824451Z","iopub.status.idle":"2023-10-25T07:40:55.842867Z","shell.execute_reply.started":"2023-10-25T07:40:55.824417Z","shell.execute_reply":"2023-10-25T07:40:55.841372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iat[2,1]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.846894Z","iopub.execute_input":"2023-10-25T07:40:55.847314Z","iopub.status.idle":"2023-10-25T07:40:55.861163Z","shell.execute_reply.started":"2023-10-25T07:40:55.847281Z","shell.execute_reply":"2023-10-25T07:40:55.860052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[1:5,1:3]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.863273Z","iopub.execute_input":"2023-10-25T07:40:55.863758Z","iopub.status.idle":"2023-10-25T07:40:55.884205Z","shell.execute_reply.started":"2023-10-25T07:40:55.863712Z","shell.execute_reply":"2023-10-25T07:40:55.882988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[1:5,['gender','age']]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.886062Z","iopub.execute_input":"2023-10-25T07:40:55.886442Z","iopub.status.idle":"2023-10-25T07:40:55.902744Z","shell.execute_reply.started":"2023-10-25T07:40:55.886397Z","shell.execute_reply":"2023-10-25T07:40:55.901725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning and Transforming\n\nData cleaning and transformation are crucial steps in the data preprocessing and analysis pipeline. Pandas provides numerous functions for cleaning and transforming data in DataFrames. Here are some common functions and techniques for data cleaning and transformation in Pandas:\n\n1. **Handling Missing Values**:\n\n   - `df.dropna()`: Removes rows or columns with missing values.\n   - `df.fillna(value)`: Fills missing values with a specified value.\n   - `df.interpolate()`: Interpolates missing values based on various methods (e.g., linear or polynomial).\n\n2. **Changing Data Types**:\n\n   - `df.astype(dtype)`: Converts the data type of one or more columns.\n   - `pd.to_numeric()`, `pd.to_datetime()`, `pd.to_timedelta()`: Converts data to specific data types.\n\n3. **Data Aggregation and Grouping**:\n\n   - `df.groupby()`: Groups data based on one or more columns for aggregation.\n   - `agg()`: Performs aggregation operations (e.g., sum, mean, count) on grouped data.\n   - `pivot_table()`: Creates pivot tables for summarizing data.\n\n4. **Renaming and Reindexing**:\n\n   - `df.rename()`: Renames columns or indexes.\n   - `df.set_index()`: Sets a specific column as the DataFrame's index.\n   - `df.reset_index()`: Resets the index.\n\n5. **Dropping Columns**:\n\n   - `df.drop(columns)`: Drops specified columns.\n   - `df.pop(column)`: Removes and returns a specific column.\n\n6. **String Manipulation**:\n\n   - `str.lower()`, `str.upper()`, `str.strip()`: Performs string operations on text columns.\n   - `str.contains()`, `str.replace()`: Searches for and replaces text in columns.\n\n7. **Duplicated Data**:\n\n   - `df.duplicated()`: Identifies duplicate rows.\n   - `df.drop_duplicates()`: Removes duplicate rows.\n\n8. **Applying Custom Functions**:\n\n   - `apply(func)`, `applymap(func)`: Applies a custom function element-wise or row-wise.\n   - `transform(func)`: Applies a custom function element-wise and retains the DataFrame shape.\n\n9. **Handling Outliers**:\n\n   - Filtering rows or replacing outlier values based on criteria.\n\n10. **Binning and Categorization**:\n\n    - `cut()`: Divides a continuous variable into categorical bins.\n    - `qcut()`: Divides a continuous variable into quantile-based bins.\n\n11. **Merging and Joining Data**:\n\n    - `concat()`, `merge()`: Combines multiple DataFrames.\n    - `join()`: Joins DataFrames on a common column.\n\n12. **Reshaping Data**:\n\n    - `melt()`: Unpivots data from wide to long format.\n    - `pivot()`: Pivots data from long to wide format.\n\n13. **Handling Datetime Data**:\n\n    - Extracting date, time, and other components from datetime columns.\n\n14. **Handling Categorical Data**:\n\n    - Encoding categorical variables into numerical format.\n\n15. **Mathematical and Statistical Transformations**:\n\n    - `df.apply()`: Apply mathematical or statistical functions row-wise or column-wise.\n\n16. **Custom Data Cleaning and Transformation**:\n\n    - Writing custom functions and transformations to address domain-specific needs.\n\nData cleaning and transformation are highly dependent on the specific dataset and analysis goals. Pandas offers a wide range of functions to support these operations, allowing you to preprocess and manipulate data effectively before analysis.","metadata":{}},{"cell_type":"markdown","source":"#### 1. **Handling Missing Values**:\n\n   - `df.dropna()`: Removes rows or columns with missing values.\n   - `df.fillna(value)`: Fills missing values with a specified value.\n   - `df.interpolate()`: Interpolates missing values based on various methods (e.g., linear or polynomial).","metadata":{}},{"cell_type":"code","source":"# dummy data\nimport pandas as pd\nimport numpy as np\n\n# Create a sample DataFrame with 20 rows\ndata = {\n    'A': np.random.randint(1, 10, 20),   # Random integers\n    'B': np.random.rand(20),             # Random float values\n    'C': np.random.choice(['X', 'Y', np.nan], 20),  # Random choice with some NaN\n    'D': [np.nan] * 10 + list(range(10))  # First 10 values are NaN\n}\n\ndf2 = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.904601Z","iopub.execute_input":"2023-10-25T07:40:55.904978Z","iopub.status.idle":"2023-10-25T07:40:55.913801Z","shell.execute_reply.started":"2023-10-25T07:40:55.904947Z","shell.execute_reply":"2023-10-25T07:40:55.912755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the DataFrame\ndf2","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.916794Z","iopub.execute_input":"2023-10-25T07:40:55.918232Z","iopub.status.idle":"2023-10-25T07:40:55.945510Z","shell.execute_reply.started":"2023-10-25T07:40:55.918185Z","shell.execute_reply":"2023-10-25T07:40:55.944171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking nan type\ntype(df2['D'][0])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.947658Z","iopub.execute_input":"2023-10-25T07:40:55.948166Z","iopub.status.idle":"2023-10-25T07:40:55.961029Z","shell.execute_reply.started":"2023-10-25T07:40:55.948121Z","shell.execute_reply":"2023-10-25T07:40:55.960007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(df2['C'][0]) \n# str nan type cannot be drop or filled by df.dropna or df.fillna, it only can be replace by another","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.963308Z","iopub.execute_input":"2023-10-25T07:40:55.963801Z","iopub.status.idle":"2023-10-25T07:40:55.977858Z","shell.execute_reply.started":"2023-10-25T07:40:55.963764Z","shell.execute_reply":"2023-10-25T07:40:55.976366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.dropna()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:55.979604Z","iopub.execute_input":"2023-10-25T07:40:55.980406Z","iopub.status.idle":"2023-10-25T07:40:56.003548Z","shell.execute_reply.started":"2023-10-25T07:40:55.980361Z","shell.execute_reply":"2023-10-25T07:40:56.002316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.fillna(\"Missing\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.006060Z","iopub.execute_input":"2023-10-25T07:40:56.007253Z","iopub.status.idle":"2023-10-25T07:40:56.023523Z","shell.execute_reply.started":"2023-10-25T07:40:56.007194Z","shell.execute_reply":"2023-10-25T07:40:56.022433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.replace(\"nan\",'Missing')\n# this will only perform on which nan type is str","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.024823Z","iopub.execute_input":"2023-10-25T07:40:56.025957Z","iopub.status.idle":"2023-10-25T07:40:56.050229Z","shell.execute_reply.started":"2023-10-25T07:40:56.025897Z","shell.execute_reply":"2023-10-25T07:40:56.049020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2. **Changing Data Types**:\n\n   - `df.astype(dtype)`: Converts the data type of one or more columns.\n   - `pd.to_numeric()`, `pd.to_datetime()`, `pd.to_timedelta()`: Converts data to specific data types.","metadata":{}},{"cell_type":"code","source":"dummy.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.051991Z","iopub.execute_input":"2023-10-25T07:40:56.052364Z","iopub.status.idle":"2023-10-25T07:40:56.071022Z","shell.execute_reply.started":"2023-10-25T07:40:56.052330Z","shell.execute_reply":"2023-10-25T07:40:56.069506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy.astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.074061Z","iopub.execute_input":"2023-10-25T07:40:56.075022Z","iopub.status.idle":"2023-10-25T07:40:56.095803Z","shell.execute_reply.started":"2023-10-25T07:40:56.074978Z","shell.execute_reply":"2023-10-25T07:40:56.094600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy['Math'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.097615Z","iopub.execute_input":"2023-10-25T07:40:56.098422Z","iopub.status.idle":"2023-10-25T07:40:56.107755Z","shell.execute_reply.started":"2023-10-25T07:40:56.098376Z","shell.execute_reply":"2023-10-25T07:40:56.106877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport string\nfrom datetime import datetime, time, timedelta\n\n# Create a list of data\ndata = []\n\n# Generate random data for 20 rows\nfor _ in range(20):\n    # Generate random datetime\n    date = datetime(2023, random.randint(1, 12), random.randint(1, 28), random.randint(0, 23), random.randint(0, 59), random.randint(0, 59))\n    \n    # Generate random time\n    start_time = time(random.randint(0, 23), random.randint(0, 59), random.randint(0, 59))\n    \n    # Generate random integer\n    integer_value = random.randint(0, 100)\n    \n    # Generate random float\n    float_value = round(random.uniform(0, 100), 2)\n    \n    # Generate random string\n    string_value = ''.join(random.choice(string.ascii_letters) for _ in range(5))\n    \n    data.append([date, start_time, integer_value, float_value, string_value])\n\n# Create a DataFrame\ndf3 = pd.DataFrame(data, columns=['Datetime', 'Time', 'Integer', 'Float', 'String'], dtype=object)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.109273Z","iopub.execute_input":"2023-10-25T07:40:56.109733Z","iopub.status.idle":"2023-10-25T07:40:56.124929Z","shell.execute_reply.started":"2023-10-25T07:40:56.109700Z","shell.execute_reply":"2023-10-25T07:40:56.123999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the DataFrame\ndf3","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.126378Z","iopub.execute_input":"2023-10-25T07:40:56.126939Z","iopub.status.idle":"2023-10-25T07:40:56.150151Z","shell.execute_reply.started":"2023-10-25T07:40:56.126894Z","shell.execute_reply":"2023-10-25T07:40:56.148802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df3.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.155390Z","iopub.execute_input":"2023-10-25T07:40:56.155853Z","iopub.status.idle":"2023-10-25T07:40:56.169179Z","shell.execute_reply.started":"2023-10-25T07:40:56.155816Z","shell.execute_reply":"2023-10-25T07:40:56.167937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# str int to int\npd.to_numeric(df3['Integer'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.170644Z","iopub.execute_input":"2023-10-25T07:40:56.171614Z","iopub.status.idle":"2023-10-25T07:40:56.180911Z","shell.execute_reply.started":"2023-10-25T07:40:56.171576Z","shell.execute_reply":"2023-10-25T07:40:56.179763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# float object to float\npd.to_numeric(df3['Float'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.182671Z","iopub.execute_input":"2023-10-25T07:40:56.183839Z","iopub.status.idle":"2023-10-25T07:40:56.199158Z","shell.execute_reply.started":"2023-10-25T07:40:56.183803Z","shell.execute_reply":"2023-10-25T07:40:56.198068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# object to datetime\npd.to_datetime(df3['Datetime'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.200974Z","iopub.execute_input":"2023-10-25T07:40:56.201669Z","iopub.status.idle":"2023-10-25T07:40:56.216310Z","shell.execute_reply.started":"2023-10-25T07:40:56.201623Z","shell.execute_reply":"2023-10-25T07:40:56.215311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract date\npd.to_datetime(df3['Datetime']).dt.date","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.217959Z","iopub.execute_input":"2023-10-25T07:40:56.219091Z","iopub.status.idle":"2023-10-25T07:40:56.231633Z","shell.execute_reply.started":"2023-10-25T07:40:56.219048Z","shell.execute_reply":"2023-10-25T07:40:56.230308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get year\npd.to_datetime(df3['Datetime']).dt.year","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.235364Z","iopub.execute_input":"2023-10-25T07:40:56.235977Z","iopub.status.idle":"2023-10-25T07:40:56.255867Z","shell.execute_reply.started":"2023-10-25T07:40:56.235900Z","shell.execute_reply":"2023-10-25T07:40:56.254929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get month\npd.to_datetime(df3['Datetime']).dt.month","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.257265Z","iopub.execute_input":"2023-10-25T07:40:56.258280Z","iopub.status.idle":"2023-10-25T07:40:56.273853Z","shell.execute_reply.started":"2023-10-25T07:40:56.258242Z","shell.execute_reply":"2023-10-25T07:40:56.272408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get month name\npd.to_datetime(df3['Datetime']).dt.month_name()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.276510Z","iopub.execute_input":"2023-10-25T07:40:56.278050Z","iopub.status.idle":"2023-10-25T07:40:56.288826Z","shell.execute_reply.started":"2023-10-25T07:40:56.277989Z","shell.execute_reply":"2023-10-25T07:40:56.287330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get day\npd.to_datetime(df3['Datetime']).dt.day","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.291095Z","iopub.execute_input":"2023-10-25T07:40:56.291536Z","iopub.status.idle":"2023-10-25T07:40:56.302609Z","shell.execute_reply.started":"2023-10-25T07:40:56.291500Z","shell.execute_reply":"2023-10-25T07:40:56.301308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get day name\npd.to_datetime(df3['Datetime']).dt.day_name()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.322999Z","iopub.execute_input":"2023-10-25T07:40:56.324181Z","iopub.status.idle":"2023-10-25T07:40:56.334796Z","shell.execute_reply.started":"2023-10-25T07:40:56.324139Z","shell.execute_reply":"2023-10-25T07:40:56.333758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get week \npd.to_datetime(df3['Datetime']).dt.weekday","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.338102Z","iopub.execute_input":"2023-10-25T07:40:56.339070Z","iopub.status.idle":"2023-10-25T07:40:56.349635Z","shell.execute_reply.started":"2023-10-25T07:40:56.339015Z","shell.execute_reply":"2023-10-25T07:40:56.348450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get time from datetime\npd.to_datetime(df3['Datetime']).dt.time","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.351469Z","iopub.execute_input":"2023-10-25T07:40:56.352363Z","iopub.status.idle":"2023-10-25T07:40:56.364490Z","shell.execute_reply.started":"2023-10-25T07:40:56.352323Z","shell.execute_reply":"2023-10-25T07:40:56.363052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get hour\npd.to_datetime(df3['Datetime']).dt.hour","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.366671Z","iopub.execute_input":"2023-10-25T07:40:56.367129Z","iopub.status.idle":"2023-10-25T07:40:56.382219Z","shell.execute_reply.started":"2023-10-25T07:40:56.367088Z","shell.execute_reply":"2023-10-25T07:40:56.381030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get minute\npd.to_datetime(df3['Datetime']).dt.minute","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.388135Z","iopub.execute_input":"2023-10-25T07:40:56.388552Z","iopub.status.idle":"2023-10-25T07:40:56.400659Z","shell.execute_reply.started":"2023-10-25T07:40:56.388518Z","shell.execute_reply":"2023-10-25T07:40:56.399418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get second\npd.to_datetime(df3['Datetime']).dt.second","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.402292Z","iopub.execute_input":"2023-10-25T07:40:56.402817Z","iopub.status.idle":"2023-10-25T07:40:56.415459Z","shell.execute_reply.started":"2023-10-25T07:40:56.402753Z","shell.execute_reply":"2023-10-25T07:40:56.414009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 3. **Data Aggregation and Grouping**:\n\n   - `df.groupby()`: Groups data based on one or more columns for aggregation.\n   - `agg()`: Performs aggregation operations (e.g., sum, mean, count) on grouped data.\n   - `pivot_table()`: Creates pivot tables for summarizing data.\n   ","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv(\"/kaggle/input/ipl-auction-20132022-data/IPl Auction 2013-2022.csv\")\nplayers = df.groupby(\"type\") # gourping on players category","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.417424Z","iopub.execute_input":"2023-10-25T07:40:56.418640Z","iopub.status.idle":"2023-10-25T07:40:56.432128Z","shell.execute_reply.started":"2023-10-25T07:40:56.418599Z","shell.execute_reply":"2023-10-25T07:40:56.431031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`df.groupby()` is a powerful method in Pandas for grouping data in a DataFrame. It returns a `GroupBy` object, which provides various methods and attributes for working with grouped data. Here are some of the commonly used attributes, methods, and variables of a `GroupBy` object:\n\n1. **`groups` (attribute)**:\n   - Returns a dictionary where the keys are the unique group labels, and the values are the corresponding group indices.","metadata":{}},{"cell_type":"code","source":"players.groups","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.433530Z","iopub.execute_input":"2023-10-25T07:40:56.434029Z","iopub.status.idle":"2023-10-25T07:40:56.446722Z","shell.execute_reply.started":"2023-10-25T07:40:56.433983Z","shell.execute_reply":"2023-10-25T07:40:56.445722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **`get_group()` (method)**:\n   - Retrieves a specific group from the grouped data. For example, `grouped.get_group('GroupLabel')` returns a DataFrame with all rows belonging to 'GroupLabel'.","metadata":{}},{"cell_type":"code","source":"players.groups.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.449106Z","iopub.execute_input":"2023-10-25T07:40:56.450113Z","iopub.status.idle":"2023-10-25T07:40:56.457756Z","shell.execute_reply.started":"2023-10-25T07:40:56.449876Z","shell.execute_reply":"2023-10-25T07:40:56.456478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.get_group('All-Rounder').head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.460131Z","iopub.execute_input":"2023-10-25T07:40:56.460612Z","iopub.status.idle":"2023-10-25T07:40:56.479012Z","shell.execute_reply.started":"2023-10-25T07:40:56.460566Z","shell.execute_reply":"2023-10-25T07:40:56.478039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.get_group(\"Bowler\").head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.480338Z","iopub.execute_input":"2023-10-25T07:40:56.480674Z","iopub.status.idle":"2023-10-25T07:40:56.497330Z","shell.execute_reply.started":"2023-10-25T07:40:56.480645Z","shell.execute_reply":"2023-10-25T07:40:56.496033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"3. **`size()` (method)**:\n   - Returns a Series with the group sizes, indicating how many rows are in each group.","metadata":{}},{"cell_type":"code","source":"players.size()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.499120Z","iopub.execute_input":"2023-10-25T07:40:56.499527Z","iopub.status.idle":"2023-10-25T07:40:56.512525Z","shell.execute_reply.started":"2023-10-25T07:40:56.499493Z","shell.execute_reply":"2023-10-25T07:40:56.511577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"4. **`count()` (method)**:\n   - Returns the count of non-null values in each group.","metadata":{}},{"cell_type":"code","source":"players.count()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.520501Z","iopub.execute_input":"2023-10-25T07:40:56.521326Z","iopub.status.idle":"2023-10-25T07:40:56.537182Z","shell.execute_reply.started":"2023-10-25T07:40:56.521287Z","shell.execute_reply":"2023-10-25T07:40:56.535557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"5. **`mean()` (method)**:\n   - Calculates the mean of each group.","metadata":{}},{"cell_type":"code","source":"players['sold_price'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.539473Z","iopub.execute_input":"2023-10-25T07:40:56.539836Z","iopub.status.idle":"2023-10-25T07:40:56.548998Z","shell.execute_reply.started":"2023-10-25T07:40:56.539805Z","shell.execute_reply":"2023-10-25T07:40:56.548038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.get_group('Batsman')['sold_price'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.550708Z","iopub.execute_input":"2023-10-25T07:40:56.551076Z","iopub.status.idle":"2023-10-25T07:40:56.564578Z","shell.execute_reply.started":"2023-10-25T07:40:56.551045Z","shell.execute_reply":"2023-10-25T07:40:56.563513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"6. **`sum()` (method)**:\n   - Calculates the sum of each group.","metadata":{}},{"cell_type":"code","source":"players['sold_price'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.566885Z","iopub.execute_input":"2023-10-25T07:40:56.567244Z","iopub.status.idle":"2023-10-25T07:40:56.581681Z","shell.execute_reply.started":"2023-10-25T07:40:56.567213Z","shell.execute_reply":"2023-10-25T07:40:56.580357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.get_group('Batsman')['sold_price'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.583315Z","iopub.execute_input":"2023-10-25T07:40:56.583702Z","iopub.status.idle":"2023-10-25T07:40:56.591763Z","shell.execute_reply.started":"2023-10-25T07:40:56.583669Z","shell.execute_reply":"2023-10-25T07:40:56.590874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"7. **`min()` (method)**:\n   - Calculates the minimum value in each group.","metadata":{}},{"cell_type":"code","source":"players['sold_price'].min()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.593438Z","iopub.execute_input":"2023-10-25T07:40:56.593843Z","iopub.status.idle":"2023-10-25T07:40:56.610303Z","shell.execute_reply.started":"2023-10-25T07:40:56.593807Z","shell.execute_reply":"2023-10-25T07:40:56.608789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"8. **`max()` (method)**:\n   - Calculates the maximum value in each group.","metadata":{}},{"cell_type":"code","source":"players['sold_price'].max()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.612265Z","iopub.execute_input":"2023-10-25T07:40:56.612661Z","iopub.status.idle":"2023-10-25T07:40:56.629078Z","shell.execute_reply.started":"2023-10-25T07:40:56.612618Z","shell.execute_reply":"2023-10-25T07:40:56.627859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"9. **`agg()` (method)**:\n   - Applies one or more aggregation functions to each group. You can pass a dictionary specifying which functions to apply to which columns.","metadata":{}},{"cell_type":"code","source":"players.agg({'sold_price': ['sum', 'mean', 'min','max']})","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.631539Z","iopub.execute_input":"2023-10-25T07:40:56.632532Z","iopub.status.idle":"2023-10-25T07:40:56.660356Z","shell.execute_reply.started":"2023-10-25T07:40:56.632482Z","shell.execute_reply":"2023-10-25T07:40:56.659090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"10. **`apply()` (method)**:\n    - Applies a custom function to each group.","metadata":{}},{"cell_type":"code","source":"players.get_group(\"Bowler\").apply(lambda x : x*1)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.663506Z","iopub.execute_input":"2023-10-25T07:40:56.664593Z","iopub.status.idle":"2023-10-25T07:40:56.690020Z","shell.execute_reply.started":"2023-10-25T07:40:56.664528Z","shell.execute_reply":"2023-10-25T07:40:56.689008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"11. **`transform()` (method)**:\n    - Applies a function to each group and broadcasts the results to the original DataFrame.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"12. **`filter()` (method)**:\n    - Filters groups based on a condition and returns a new GroupBy object containing only the selected groups.","metadata":{}},{"cell_type":"markdown","source":"13. **`describe()` (method)**:\n    - Generates descriptive statistics for each group, similar to the `describe()` method for DataFrames.","metadata":{}},{"cell_type":"code","source":"players.count().describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.692234Z","iopub.execute_input":"2023-10-25T07:40:56.692703Z","iopub.status.idle":"2023-10-25T07:40:56.728620Z","shell.execute_reply.started":"2023-10-25T07:40:56.692670Z","shell.execute_reply":"2023-10-25T07:40:56.727671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"14. **`head()` and `tail()` (method)**:\n    - Returns the first or last n rows of each group.","metadata":{}},{"cell_type":"code","source":"players.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.730211Z","iopub.execute_input":"2023-10-25T07:40:56.731276Z","iopub.status.idle":"2023-10-25T07:40:56.748508Z","shell.execute_reply.started":"2023-10-25T07:40:56.731234Z","shell.execute_reply":"2023-10-25T07:40:56.747576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.tail()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.750081Z","iopub.execute_input":"2023-10-25T07:40:56.751107Z","iopub.status.idle":"2023-10-25T07:40:56.771181Z","shell.execute_reply.started":"2023-10-25T07:40:56.751056Z","shell.execute_reply":"2023-10-25T07:40:56.769813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"15. **`nth()` (method)**:\n    - Returns the nth row from each group.","metadata":{}},{"cell_type":"code","source":"players.nth(3)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.773186Z","iopub.execute_input":"2023-10-25T07:40:56.773722Z","iopub.status.idle":"2023-10-25T07:40:56.793334Z","shell.execute_reply.started":"2023-10-25T07:40:56.773687Z","shell.execute_reply":"2023-10-25T07:40:56.792161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"16. **`first()` and `last()` (method)**:\n    - Returns the first or last row from each group.","metadata":{}},{"cell_type":"code","source":"players.first()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.796076Z","iopub.execute_input":"2023-10-25T07:40:56.796604Z","iopub.status.idle":"2023-10-25T07:40:56.815474Z","shell.execute_reply.started":"2023-10-25T07:40:56.796568Z","shell.execute_reply":"2023-10-25T07:40:56.814052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.last()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.817589Z","iopub.execute_input":"2023-10-25T07:40:56.818093Z","iopub.status.idle":"2023-10-25T07:40:56.839810Z","shell.execute_reply.started":"2023-10-25T07:40:56.818059Z","shell.execute_reply":"2023-10-25T07:40:56.838306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"17. **`mean()`, `sum()`, `std()`, and other aggregation methods**:\n    - These methods can be used to calculate various statistics for each group.","metadata":{}},{"cell_type":"code","source":"players['sold_price'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.841912Z","iopub.execute_input":"2023-10-25T07:40:56.842305Z","iopub.status.idle":"2023-10-25T07:40:56.851441Z","shell.execute_reply.started":"2023-10-25T07:40:56.842272Z","shell.execute_reply":"2023-10-25T07:40:56.850128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players['sold_price'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.853175Z","iopub.execute_input":"2023-10-25T07:40:56.854049Z","iopub.status.idle":"2023-10-25T07:40:56.867083Z","shell.execute_reply.started":"2023-10-25T07:40:56.854001Z","shell.execute_reply":"2023-10-25T07:40:56.865628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players['sold_price'].std()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.869720Z","iopub.execute_input":"2023-10-25T07:40:56.870811Z","iopub.status.idle":"2023-10-25T07:40:56.883179Z","shell.execute_reply.started":"2023-10-25T07:40:56.870772Z","shell.execute_reply":"2023-10-25T07:40:56.881981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players['sold_price'].min()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.884659Z","iopub.execute_input":"2023-10-25T07:40:56.886111Z","iopub.status.idle":"2023-10-25T07:40:56.896426Z","shell.execute_reply.started":"2023-10-25T07:40:56.886069Z","shell.execute_reply":"2023-10-25T07:40:56.895297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players['sold_price'].max()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.898027Z","iopub.execute_input":"2023-10-25T07:40:56.899133Z","iopub.status.idle":"2023-10-25T07:40:56.915029Z","shell.execute_reply.started":"2023-10-25T07:40:56.899080Z","shell.execute_reply":"2023-10-25T07:40:56.914029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"18. **`size()`, `count()`, `first()`, `last()`, and other counting and selection methods**:\n    - These methods help in summarizing and selecting data based on group properties.","metadata":{}},{"cell_type":"code","source":"players.size()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.917414Z","iopub.execute_input":"2023-10-25T07:40:56.918098Z","iopub.status.idle":"2023-10-25T07:40:56.928111Z","shell.execute_reply.started":"2023-10-25T07:40:56.918060Z","shell.execute_reply":"2023-10-25T07:40:56.926865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.count()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.929968Z","iopub.execute_input":"2023-10-25T07:40:56.930484Z","iopub.status.idle":"2023-10-25T07:40:56.948613Z","shell.execute_reply.started":"2023-10-25T07:40:56.930441Z","shell.execute_reply":"2023-10-25T07:40:56.947334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.first()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.951149Z","iopub.execute_input":"2023-10-25T07:40:56.951553Z","iopub.status.idle":"2023-10-25T07:40:56.969725Z","shell.execute_reply.started":"2023-10-25T07:40:56.951519Z","shell.execute_reply":"2023-10-25T07:40:56.968811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"players.last()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.971496Z","iopub.execute_input":"2023-10-25T07:40:56.972769Z","iopub.status.idle":"2023-10-25T07:40:56.988276Z","shell.execute_reply.started":"2023-10-25T07:40:56.972727Z","shell.execute_reply":"2023-10-25T07:40:56.986999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The specific method you use will depend on your data analysis needs. These functions allow you to perform group-wise operations and calculations on your data, making groupby an essential tool for data analysis with Pandas.","metadata":{}},{"cell_type":"markdown","source":"#### 4. **Renaming and Reindexing**:\n\n   - `df.rename()`: Renames columns or indexes.\n   - `df.set_index()`: Sets a specific column as the DataFrame's index.\n   - `df.reset_index()`: Resets the index.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:56.990218Z","iopub.execute_input":"2023-10-25T07:40:56.990738Z","iopub.status.idle":"2023-10-25T07:40:57.004393Z","shell.execute_reply.started":"2023-10-25T07:40:56.990681Z","shell.execute_reply":"2023-10-25T07:40:57.003444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = df.rename(columns={'player_name':'Name', 'nationality':'Nationality', 'type':'Type', 'teams':'Teams', 'year':'Year', 'sponsored_by':'Sponsored_By','sold_price':'Sold_Price'})","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.006277Z","iopub.execute_input":"2023-10-25T07:40:57.007609Z","iopub.status.idle":"2023-10-25T07:40:57.018039Z","shell.execute_reply.started":"2023-10-25T07:40:57.007568Z","shell.execute_reply":"2023-10-25T07:40:57.016640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.019586Z","iopub.execute_input":"2023-10-25T07:40:57.020812Z","iopub.status.idle":"2023-10-25T07:40:57.037297Z","shell.execute_reply.started":"2023-10-25T07:40:57.020772Z","shell.execute_reply":"2023-10-25T07:40:57.036019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.set_index('player_name')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.040001Z","iopub.execute_input":"2023-10-25T07:40:57.040407Z","iopub.status.idle":"2023-10-25T07:40:57.065825Z","shell.execute_reply.started":"2023-10-25T07:40:57.040359Z","shell.execute_reply":"2023-10-25T07:40:57.064490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.index","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.067213Z","iopub.execute_input":"2023-10-25T07:40:57.067573Z","iopub.status.idle":"2023-10-25T07:40:57.075763Z","shell.execute_reply.started":"2023-10-25T07:40:57.067541Z","shell.execute_reply":"2023-10-25T07:40:57.074433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.079074Z","iopub.execute_input":"2023-10-25T07:40:57.079490Z","iopub.status.idle":"2023-10-25T07:40:57.100432Z","shell.execute_reply.started":"2023-10-25T07:40:57.079455Z","shell.execute_reply":"2023-10-25T07:40:57.099218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 5. **Dropping Columns**:\n\n   - `df.drop(columns)`: Drops specified columns.\n   - `df.pop(column)`: Removes and returns a specific column.","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.102456Z","iopub.execute_input":"2023-10-25T07:40:57.103149Z","iopub.status.idle":"2023-10-25T07:40:57.116945Z","shell.execute_reply.started":"2023-10-25T07:40:57.103103Z","shell.execute_reply":"2023-10-25T07:40:57.115512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns='nationality')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.120195Z","iopub.execute_input":"2023-10-25T07:40:57.121112Z","iopub.status.idle":"2023-10-25T07:40:57.149051Z","shell.execute_reply.started":"2023-10-25T07:40:57.121064Z","shell.execute_reply":"2023-10-25T07:40:57.147678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(columns=['nationality','year'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.150751Z","iopub.execute_input":"2023-10-25T07:40:57.151473Z","iopub.status.idle":"2023-10-25T07:40:57.177317Z","shell.execute_reply.started":"2023-10-25T07:40:57.151435Z","shell.execute_reply":"2023-10-25T07:40:57.175255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.pop('sponsored_by')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.179066Z","iopub.execute_input":"2023-10-25T07:40:57.179463Z","iopub.status.idle":"2023-10-25T07:40:57.190351Z","shell.execute_reply.started":"2023-10-25T07:40:57.179428Z","shell.execute_reply":"2023-10-25T07:40:57.188951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.193795Z","iopub.execute_input":"2023-10-25T07:40:57.194565Z","iopub.status.idle":"2023-10-25T07:40:57.215381Z","shell.execute_reply.started":"2023-10-25T07:40:57.194526Z","shell.execute_reply":"2023-10-25T07:40:57.213734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 6. **String Manipulation**:\n\n   - `str.lower()`, `str.upper()`, `str.strip()`: Performs string operations on text columns.\n   - `str.contains()`, `str.replace()`: Searches for and replaces text in columns.","metadata":{}},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.217136Z","iopub.execute_input":"2023-10-25T07:40:57.217623Z","iopub.status.idle":"2023-10-25T07:40:57.235524Z","shell.execute_reply.started":"2023-10-25T07:40:57.217575Z","shell.execute_reply":"2023-10-25T07:40:57.234579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['player_name'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.236720Z","iopub.execute_input":"2023-10-25T07:40:57.237502Z","iopub.status.idle":"2023-10-25T07:40:57.252881Z","shell.execute_reply.started":"2023-10-25T07:40:57.237467Z","shell.execute_reply":"2023-10-25T07:40:57.252013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['player_name'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.254074Z","iopub.execute_input":"2023-10-25T07:40:57.255193Z","iopub.status.idle":"2023-10-25T07:40:57.273143Z","shell.execute_reply.started":"2023-10-25T07:40:57.255147Z","shell.execute_reply":"2023-10-25T07:40:57.271783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['player_name'].str.strip()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.276165Z","iopub.execute_input":"2023-10-25T07:40:57.277081Z","iopub.status.idle":"2023-10-25T07:40:57.288760Z","shell.execute_reply.started":"2023-10-25T07:40:57.277043Z","shell.execute_reply":"2023-10-25T07:40:57.287495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 7. **Duplicated Data**:\n\n   - `df.duplicated()`: Identifies duplicate rows.\n   - `df.drop_duplicates()`: Removes duplicate rows.","metadata":{}},{"cell_type":"code","source":"excel_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.290748Z","iopub.execute_input":"2023-10-25T07:40:57.291264Z","iopub.status.idle":"2023-10-25T07:40:57.308656Z","shell.execute_reply.started":"2023-10-25T07:40:57.291196Z","shell.execute_reply":"2023-10-25T07:40:57.307762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df[excel_df.duplicated()]","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.310025Z","iopub.execute_input":"2023-10-25T07:40:57.310579Z","iopub.status.idle":"2023-10-25T07:40:57.332534Z","shell.execute_reply.started":"2023-10-25T07:40:57.310546Z","shell.execute_reply":"2023-10-25T07:40:57.331598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df.drop_duplicates(keep='first')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.334136Z","iopub.execute_input":"2023-10-25T07:40:57.334725Z","iopub.status.idle":"2023-10-25T07:40:57.366151Z","shell.execute_reply.started":"2023-10-25T07:40:57.334683Z","shell.execute_reply":"2023-10-25T07:40:57.364799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excel_df.drop_duplicates(keep='first').duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.367642Z","iopub.execute_input":"2023-10-25T07:40:57.368637Z","iopub.status.idle":"2023-10-25T07:40:57.386277Z","shell.execute_reply.started":"2023-10-25T07:40:57.368598Z","shell.execute_reply":"2023-10-25T07:40:57.384836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 8. **Applying Custom Functions**:\n\n   - `apply(func)`, `applymap(func)`: Applies a custom function element-wise or row-wise.\n   - `transform(func)`: Applies a custom function element-wise and retains the DataFrame shape.\n   \n``` python \ndf.apply(func, axis=0)  # Apply 'func' to each column\ndf.apply(func, axis=1)  # Apply 'func' to each row\n\ndf.applymap(func)  # Apply 'func' to each element in the DataFrame\n\nseries.map(func)  # Apply 'func' to each element in the Series\n\ndf.groupby('grouping_column').agg(func)  # Apply aggregation functions to groups\ndf.groupby('grouping_column').transform(func)  # Apply a function to each group and broadcast the results\ndf.groupby('grouping_column').filter(lambda x: condition(x))  # Filter groups based on a condition\n\n\n```\n","metadata":{}},{"cell_type":"code","source":"# creating a custom function\ndef format_large_number(number):\n    if number < 1000:\n        return str(number)\n    elif number < 1e6:\n        return f'{number / 1e3:.1f}K'\n    elif number < 1e9:\n        return f'{number / 1e6:.1f}M'\n    else:\n        return f'{number / 1e9:.1f}B'\n\n# Test the function with some examples\nnumber1 = 10000\nnumber2 = 2000000\nnumber3 = 2500000000\n\nformatted1 = format_large_number(number1)\nformatted2 = format_large_number(number2)\nformatted3 = format_large_number(number3)\n\nprint(formatted1)  # Output: 10.0K\nprint(formatted2)  # Output: 2.0M\nprint(formatted3)  # Output: 2.5B","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.387899Z","iopub.execute_input":"2023-10-25T07:40:57.388473Z","iopub.status.idle":"2023-10-25T07:40:57.401628Z","shell.execute_reply.started":"2023-10-25T07:40:57.388439Z","shell.execute_reply":"2023-10-25T07:40:57.400734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sold_price']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.402896Z","iopub.execute_input":"2023-10-25T07:40:57.403456Z","iopub.status.idle":"2023-10-25T07:40:57.418910Z","shell.execute_reply.started":"2023-10-25T07:40:57.403425Z","shell.execute_reply":"2023-10-25T07:40:57.418052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['sold_price'].apply(format_large_number)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.422616Z","iopub.execute_input":"2023-10-25T07:40:57.423094Z","iopub.status.idle":"2023-10-25T07:40:57.435582Z","shell.execute_reply.started":"2023-10-25T07:40:57.423059Z","shell.execute_reply":"2023-10-25T07:40:57.434137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 9. **Handling Outliers**:\n\n   - Filtering rows or replacing outlier values based on criteria.","metadata":{}},{"cell_type":"markdown","source":"Handling outliers in a dataset is an important step in data preprocessing and analysis. Outliers are data points that significantly differ from the majority of the data and can distort statistical analyses and machine learning models. Pandas offers several methods to handle outliers:\n\n1. **Identifying Outliers:**\n   - Before handling outliers, you need to identify them. You can use descriptive statistics, visualizations, or statistical tests to identify outliers in your data.\n\n2. **Removing Outliers:**\n   - One common approach is to remove outliers from the dataset. You can do this by filtering the data based on certain criteria. For example, you can remove data points that fall outside a specified range or z-score threshold.\n\n   ```python\n   # Removing outliers based on z-score\n   from scipy import stats\n   z_scores = stats.zscore(df['column_to_check'])\n   df_no_outliers = df[(z_scores < 3) & (z_scores > -3)]\n   ```\n\n3. **Replacing Outliers:**\n   - Instead of removing outliers, you can replace them with more reasonable values. You might replace them with the mean, median, or a custom value.\n\n   ```python\n   # Replacing outliers with the median\n   median_value = df['column_to_check'].median()\n   df['column_to_check'] = df['column_to_check'].apply(lambda x: median_value if x > threshold else x)\n   ```\n\n4. **Transforming Data:**\n   - You can transform the data to make it more robust to outliers. Common transformations include log transformation or using the Tukey fence.\n\n   ```python\n   # Log transformation\n   df['column_to_check'] = np.log(df['column_to_check'])\n   ```\n\n5. **Clipping Data:**\n   - Another option is to clip the data, which caps the extreme values at a predefined threshold.\n\n   ```python\n   # Clipping data\n   df['column_to_check'] = df['column_to_check'].clip(lower=min_value, upper=max_value)\n   ```\n\n6. **Winsorization:**\n   - Winsorization is a method where you replace outliers with the nearest non-outlier value.\n\n   ```python\n   from scipy.stats.mstats import winsorize\n   winsorized_data = winsorize(df['column_to_check'], limits=[0.05, 0.05])\n   ```\n\n7. **Robust Statistics:**\n   - Using robust statistical methods like the median instead of the mean can make your analysis less sensitive to outliers.\n\n8. **Machine Learning Models:**\n   - Some machine learning models can handle outliers effectively, or you can use techniques like robust regression.\n\nThe approach you choose depends on your specific data, the nature of the outliers, and the goals of your analysis. Always consider the domain and context when deciding how to handle outliers in your dataset.","metadata":{}},{"cell_type":"markdown","source":"#### 10. **Binning and Categorization**:\n\n    - `cut()`: Divides a continuous variable into categorical bins.\n    - `qcut()`: Divides a continuous variable into quantile-based bins.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata = {'Date': pd.date_range(start='2023-01-01', periods=30, freq='D'),\n        'Temperature (C)': [5, 12, 18, 24, 30, 35, 10, 15, 22, 28, 32, 38, 7, 14, 19, 26, 33, 40, 9, 16, 21, 27, 31, 36, 8, 13, 17, 23, 29, 34]}\n\ndf = pd.DataFrame(data)\n\n# Define temperature bins\ntemperature_bins = [0, 10, 25, 40]\ntemperature_labels = ['Cold', 'Moderate', 'Hot']\n\n# Create a new column with temperature categories\ndf['Temperature Category'] = pd.cut(df['Temperature (C)'], bins=temperature_bins, labels=temperature_labels)\n\nprint(df)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.436959Z","iopub.execute_input":"2023-10-25T07:40:57.437310Z","iopub.status.idle":"2023-10-25T07:40:57.458231Z","shell.execute_reply.started":"2023-10-25T07:40:57.437280Z","shell.execute_reply":"2023-10-25T07:40:57.456852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `pd.cut()` function in Pandas is used to perform binning or categorization of data, which is the process of converting continuous numerical data into discrete categories or bins. It's particularly useful when you want to group data into intervals or categories for analysis, visualization, or modeling.\n\nHere's how to use `pd.cut()` with a simple example:","metadata":{"execution":{"iopub.status.busy":"2023-10-25T04:03:36.987665Z","iopub.execute_input":"2023-10-25T04:03:36.988287Z","iopub.status.idle":"2023-10-25T04:03:37.005868Z","shell.execute_reply.started":"2023-10-25T04:03:36.988243Z","shell.execute_reply":"2023-10-25T04:03:37.004121Z"}}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata = {'Age': [25, 32, 45, 18, 63, 29, 55, 41, 37, 50]}\ndf = pd.DataFrame(data)\n\n# Define bins for age groups\nage_bins = [0, 18, 30, 40, 60, 100]\nage_labels = ['<18', '18-30', '31-40', '41-60', '60+']\n\n# Create a new column with age categories\ndf['Age Group'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.459746Z","iopub.execute_input":"2023-10-25T07:40:57.460490Z","iopub.status.idle":"2023-10-25T07:40:57.479228Z","shell.execute_reply.started":"2023-10-25T07:40:57.460455Z","shell.execute_reply":"2023-10-25T07:40:57.477968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, we:\n\n1. Import Pandas and create a DataFrame with a column 'Age' containing age values.\n\n2. Define the bins and labels for age groups. We have defined five bins with corresponding labels, categorizing individuals into age groups.\n\n3. Use `pd.cut()` to create a new column 'Age Group' in the DataFrame. This new column contains the age categories based on the specified bins and labels.\n\nThe resulting DataFrame will have the 'Age Group' column, where each individual's age is categorized into one of the specified age groups.\n\nThe `pd.cut()` function allows you to specify custom bins and labels, providing you with flexibility in categorizing your data based on your specific requirements. It's a powerful tool for data transformation and preparation for analysis or visualization tasks.","metadata":{"execution":{"iopub.status.busy":"2023-10-25T04:03:36.987665Z","iopub.execute_input":"2023-10-25T04:03:36.988287Z","iopub.status.idle":"2023-10-25T04:03:37.005868Z","shell.execute_reply.started":"2023-10-25T04:03:36.988243Z","shell.execute_reply":"2023-10-25T04:03:37.004121Z"}}},{"cell_type":"markdown","source":"The `pd.qcut()` function in Pandas is used for quantile-based binning, which divides continuous data into discrete intervals or bins such that each bin contains approximately the same number of data points. This is useful when you want to create bins that have a balanced number of data points, making it especially helpful for equal-frequency binning.\n\nHere's how to use `pd.qcut()` with an example:","metadata":{"execution":{"iopub.status.busy":"2023-10-25T04:06:21.488426Z","iopub.execute_input":"2023-10-25T04:06:21.488915Z","iopub.status.idle":"2023-10-25T04:06:21.500566Z","shell.execute_reply.started":"2023-10-25T04:06:21.488880Z","shell.execute_reply":"2023-10-25T04:06:21.498265Z"}}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata = {'Scores': [70, 82, 60, 90, 78, 55, 88, 92, 75, 68]}\ndf = pd.DataFrame(data)\n\n# Use qcut to create quantile-based bins\nquantile_bins = pd.qcut(df['Scores'], q=3, labels=['Low', 'Medium', 'High'])\n\ndf['Score Category'] = quantile_bins\n\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.480459Z","iopub.execute_input":"2023-10-25T07:40:57.480809Z","iopub.status.idle":"2023-10-25T07:40:57.503563Z","shell.execute_reply.started":"2023-10-25T07:40:57.480780Z","shell.execute_reply":"2023-10-25T07:40:57.502574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, we:\n\n1. Import Pandas and create a DataFrame with a column 'Scores' containing numerical values.\n\n2. Use `pd.qcut()` to create quantile-based bins. The `q` parameter specifies the number of quantiles or bins you want to create, and `labels` allow you to assign labels to each bin. In this case, we create three quantile-based bins labeled as 'Low,' 'Medium,' and 'High.'\n\n3. Add a new column, 'Score Category,' to the DataFrame to store the quantile-based categories.\n\nThe resulting DataFrame will have the 'Score Category' column, with each individual's score categorized into one of the quantile-based bins. The `pd.qcut()` function ensures that each bin contains approximately the same number of data points, making it suitable for equal-frequency binning and avoiding bias in the bin sizes.\n\n`pd.qcut()` is particularly useful when you want to categorize data into intervals based on the distribution of the data itself, ensuring that you have a balanced representation in each category.","metadata":{}},{"cell_type":"markdown","source":"#### 11. **Merging and Joining Data**:\n\n    - `concat()`, `merge()`: Combines multiple DataFrames.\n    - `join()`: Joins DataFrames on a common column.","metadata":{}},{"cell_type":"markdown","source":"Merging and joining data in Pandas is a crucial operation when working with multiple DataFrames. These operations allow you to combine or join data from different sources based on common columns or keys. Here's an overview of the key functions for merging and joining data in Pandas:\n\n1. **`pd.concat()`:**\n   - The `pd.concat()` function is used to concatenate or stack multiple DataFrames along a particular axis (either rows or columns). It is useful when you want to combine data from different DataFrames without regard to their indexes.\n   \n   ```python\n   concatenated = pd.concat([df1, df2], axis=0)  # Concatenate vertically (along rows)\n   concatenated = pd.concat([df1, df2], axis=1)  # Concatenate horizontally (along columns)\n   ```","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata1 = {'A': ['A0', 'A1', 'A2'],\n         'B': ['B0', 'B1', 'B2']}\ndata2 = {'A': ['A3', 'A4', 'A5'],\n         'B': ['B3', 'B4', 'B5']}\ndf1 = pd.DataFrame(data1)\ndf2 = pd.DataFrame(data2)\n\n# Concatenate vertically (along rows)\nconcatenated = pd.concat([df1, df2], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.505025Z","iopub.execute_input":"2023-10-25T07:40:57.506332Z","iopub.status.idle":"2023-10-25T07:40:57.515962Z","shell.execute_reply.started":"2023-10-25T07:40:57.506280Z","shell.execute_reply":"2023-10-25T07:40:57.514659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.517453Z","iopub.execute_input":"2023-10-25T07:40:57.517944Z","iopub.status.idle":"2023-10-25T07:40:57.536159Z","shell.execute_reply.started":"2023-10-25T07:40:57.517880Z","shell.execute_reply":"2023-10-25T07:40:57.534875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.537573Z","iopub.execute_input":"2023-10-25T07:40:57.538044Z","iopub.status.idle":"2023-10-25T07:40:57.556502Z","shell.execute_reply.started":"2023-10-25T07:40:57.537998Z","shell.execute_reply":"2023-10-25T07:40:57.555264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concatenated","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.558478Z","iopub.execute_input":"2023-10-25T07:40:57.559273Z","iopub.status.idle":"2023-10-25T07:40:57.574857Z","shell.execute_reply.started":"2023-10-25T07:40:57.559227Z","shell.execute_reply":"2023-10-25T07:40:57.573462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data\ndata1 = {'A': ['A0', 'A1', 'A2'],\n         'B': ['B0', 'B1', 'B2']}\ndata2 = {'C': ['C0', 'C1', 'C2'],\n         'D': ['D0', 'D1', 'D2']}\ndf1 = pd.DataFrame(data1)\ndf2 = pd.DataFrame(data2)\n\n# Concatenate horizontally (along columns)\nconcatenated = pd.concat([df1, df2], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.576611Z","iopub.execute_input":"2023-10-25T07:40:57.576994Z","iopub.status.idle":"2023-10-25T07:40:57.590800Z","shell.execute_reply.started":"2023-10-25T07:40:57.576957Z","shell.execute_reply":"2023-10-25T07:40:57.589675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.596098Z","iopub.execute_input":"2023-10-25T07:40:57.596534Z","iopub.status.idle":"2023-10-25T07:40:57.615911Z","shell.execute_reply.started":"2023-10-25T07:40:57.596497Z","shell.execute_reply":"2023-10-25T07:40:57.614757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.617707Z","iopub.execute_input":"2023-10-25T07:40:57.618416Z","iopub.status.idle":"2023-10-25T07:40:57.636121Z","shell.execute_reply.started":"2023-10-25T07:40:57.618376Z","shell.execute_reply":"2023-10-25T07:40:57.635063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concatenated","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.637629Z","iopub.execute_input":"2023-10-25T07:40:57.638055Z","iopub.status.idle":"2023-10-25T07:40:57.656126Z","shell.execute_reply.started":"2023-10-25T07:40:57.638020Z","shell.execute_reply":"2023-10-25T07:40:57.654998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2. **`pd.merge()`:**\n   - The `pd.merge()` function is used to perform database-style joins on DataFrames. It allows you to combine DataFrames based on common columns or keys, similar to SQL joins. You can specify the type of join (inner, outer, left, or right) and the columns on which to join.\n   \n   ```python\n   merged = pd.merge(df1, df2, on='common_column', how='inner')  # Inner join\n   ```","metadata":{}},{"cell_type":"markdown","source":"The `pd.merge()` function in Pandas is used to combine two or more DataFrames based on common columns or keys, similar to how SQL joins work. Let's go through an example to demonstrate how to use `pd.merge()`:\n\nSuppose you have two DataFrames, `df1` and `df2`, and you want to merge them based on a common column called \"Key.\"\n\n**Example: Merging DataFrames with `pd.merge()`**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data for df1\ndata1 = {'Key': ['A', 'B', 'C', 'D'],\n         'Value1': [1, 2, 3, 4]}\ndf1 = pd.DataFrame(data1)\n\n# Sample data for df2\ndata2 = {'Key': ['B', 'D', 'E', 'F'],\n         'Value2': [5, 6, 7, 8]}\ndf2 = pd.DataFrame(data2)\n\n# Merge df1 and df2 based on the 'Key' column\nmerged = pd.merge(df1, df2, on='Key', how='inner')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.657817Z","iopub.execute_input":"2023-10-25T07:40:57.658192Z","iopub.status.idle":"2023-10-25T07:40:57.674193Z","shell.execute_reply.started":"2023-10-25T07:40:57.658160Z","shell.execute_reply":"2023-10-25T07:40:57.672851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.675874Z","iopub.execute_input":"2023-10-25T07:40:57.676344Z","iopub.status.idle":"2023-10-25T07:40:57.688068Z","shell.execute_reply.started":"2023-10-25T07:40:57.676308Z","shell.execute_reply":"2023-10-25T07:40:57.686551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.689511Z","iopub.execute_input":"2023-10-25T07:40:57.689859Z","iopub.status.idle":"2023-10-25T07:40:57.709413Z","shell.execute_reply.started":"2023-10-25T07:40:57.689828Z","shell.execute_reply":"2023-10-25T07:40:57.708254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.710806Z","iopub.execute_input":"2023-10-25T07:40:57.711910Z","iopub.status.idle":"2023-10-25T07:40:57.727713Z","shell.execute_reply.started":"2023-10-25T07:40:57.711866Z","shell.execute_reply":"2023-10-25T07:40:57.726608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, we:\n\n1. Import Pandas and create two DataFrames, `df1` and `df2`, each with a 'Key' column.\n\n2. Use `pd.merge()` to merge `df1` and `df2` based on the 'Key' column. We specify `on='Key'` to indicate that we want to merge on the 'Key' column.\n\n3. We also specify `how='inner'` to perform an inner join. An inner join includes only the common 'Key' values present in both DataFrames. Other options for `how` include 'left,' 'right,' and 'outer' to perform left, right, or full outer joins, respectively.\n\nThe resulting `merged` DataFrame will contain only the rows with common 'Key' values from both `df1` and `df2`. In this case, it will contain rows with 'Key' values 'B' and 'D.'\n\nOutput of the `merged` DataFrame:\n\n```\n  Key  Value1  Value2\n0   B       2       5\n1   D       4       6\n```\n\nThis demonstrates how `pd.merge()` is used to perform various types of joins, such as inner, left, right, or outer joins, based on common columns or keys in different DataFrames. It's a powerful tool for integrating and combining data from multiple sources.","metadata":{}},{"cell_type":"markdown","source":"3. **`.join()`:**\n   - The `.join()` method is used to join two DataFrames based on a common column, typically the index column. It provides a convenient way to perform left or right joins.\n   \n   ```python\n   df1.join(df2, how='left')  # Left join\n   ```\n\nThese functions and methods are powerful tools for combining data from different sources into a single DataFrame, either by stacking them (using `pd.concat()`) or by merging them (using `pd.merge()` or `.join()`).\n\nIn addition to these, you can specify key columns, handle duplicate column names, and perform more complex merging and joining operations, including merging on multiple columns or keys.\n\nThe choice of which method to use depends on the specific requirements of your data and the type of merge or join operation you want to perform. Understanding the different types of joins (inner, outer, left, right) and how to specify key columns is important when working with these functions.","metadata":{}},{"cell_type":"markdown","source":"In Pandas, the `.join()` method is used to combine two DataFrames based on a common column or index. The `.join()` method is more commonly used when you want to join DataFrames on their indices. Let's go through an example to demonstrate how to use `.join()`:\n\nSuppose you have two DataFrames, `df1` and `df2`, and you want to join them based on their indices or a common column, such as \"Key.\"\n\n**Example: Joining DataFrames with `.join()`**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data for df1\ndata1 = {'Key': ['A', 'B', 'C', 'D'],\n         'Value1': [1, 2, 3, 4]}\ndf1 = pd.DataFrame(data1)\n\n# Sample data for df2\ndata2 = {'Value2': [5, 6, 7, 8]}\ndf2 = pd.DataFrame(data2, index=['B', 'D', 'E', 'F'])\n\n# Join df1 and df2 based on their indices\njoined = df1.set_index('Key').join(df2, how='left')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.729277Z","iopub.execute_input":"2023-10-25T07:40:57.730269Z","iopub.status.idle":"2023-10-25T07:40:57.742987Z","shell.execute_reply.started":"2023-10-25T07:40:57.730221Z","shell.execute_reply":"2023-10-25T07:40:57.742018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.744621Z","iopub.execute_input":"2023-10-25T07:40:57.745354Z","iopub.status.idle":"2023-10-25T07:40:57.760322Z","shell.execute_reply.started":"2023-10-25T07:40:57.745310Z","shell.execute_reply":"2023-10-25T07:40:57.759009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.762493Z","iopub.execute_input":"2023-10-25T07:40:57.763160Z","iopub.status.idle":"2023-10-25T07:40:57.777100Z","shell.execute_reply.started":"2023-10-25T07:40:57.763116Z","shell.execute_reply":"2023-10-25T07:40:57.775600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"joined","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.782161Z","iopub.execute_input":"2023-10-25T07:40:57.783604Z","iopub.status.idle":"2023-10-25T07:40:57.794563Z","shell.execute_reply.started":"2023-10-25T07:40:57.783457Z","shell.execute_reply":"2023-10-25T07:40:57.793586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, we:\n\n1. Import Pandas and create two DataFrames, `df1` and `df2`. `df1` has a 'Key' column, and `df2` has a 'Value2' column.\n\n2. Use `.set_index('Key')` to set the 'Key' column as the index in `df1`. This prepares `df1` for the join.\n\n3. Use the `.join()` method to join `df1` and `df2`. We specify `how='left'` to perform a left join, keeping all rows from `df1` and matching rows from `df2`.\n\nThe resulting `joined` DataFrame will be based on the indices of `df1` and will contain values from both DataFrames, aligning them based on the common 'Key' values.\n\nOutput of the `joined` DataFrame:\n\n```\n     Value1  Value2\nKey                \nA         1     NaN\nB         2     5.0\nC         3     NaN\nD         4     6.0\n```\n\nThis demonstrates how to use the `.join()` method in Pandas to combine DataFrames based on common indices or columns. It's a convenient way to align and combine data from different sources.","metadata":{}},{"cell_type":"markdown","source":"12. **Reshaping Data**:\n\n    - `melt()`: Unpivots data from wide to long format.\n    - `pivot()`: Pivots data from long to wide format.\n    \n    In Pandas, the `melt()` and `pivot()` functions are used for transforming data between \"wide\" and \"long\" formats. These operations are commonly used for reshaping data for various analysis and visualization tasks.\n\n**`melt()`: Unpivoting Data (Wide to Long Format)**\n\nThe `melt()` function is used to unpivot or melt data from a wide format to a long format. It reshapes the data by converting columns into rows. This can be helpful when you want to analyze data in a more structured or tabular way.\n\nHere's an example of how to use `melt()`:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data in wide format\ndata = {'Date': ['2023-01-01', '2023-01-02'],\n        'Temperature_NY': [32, 35],\n        'Temperature_LA': [70, 72]}\n\ndf_wide = pd.DataFrame(data)\n\n# Melt the data to long format\ndf_long = pd.melt(df_wide, id_vars=['Date'], var_name='City', value_name='Temperature')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.795829Z","iopub.execute_input":"2023-10-25T07:40:57.797147Z","iopub.status.idle":"2023-10-25T07:40:57.813897Z","shell.execute_reply.started":"2023-10-25T07:40:57.797110Z","shell.execute_reply":"2023-10-25T07:40:57.812523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_wide","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.815587Z","iopub.execute_input":"2023-10-25T07:40:57.816037Z","iopub.status.idle":"2023-10-25T07:40:57.839900Z","shell.execute_reply.started":"2023-10-25T07:40:57.816002Z","shell.execute_reply":"2023-10-25T07:40:57.838769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_long","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.842828Z","iopub.execute_input":"2023-10-25T07:40:57.843338Z","iopub.status.idle":"2023-10-25T07:40:57.860242Z","shell.execute_reply.started":"2023-10-25T07:40:57.843287Z","shell.execute_reply":"2023-10-25T07:40:57.858901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, `melt()` is used to unpivot the data from a wide format where temperatures for different cities are in separate columns to a long format where temperatures are in rows.\n\n**`pivot()`: Pivoting Data (Long to Wide Format)**\n\nThe `pivot()` function, on the other hand, is used to pivot data from a long format to a wide format. It reshapes the data by converting unique values in a column into new columns. This can be useful when you want to create a more structured summary of the data.\n\nHere's an example of how to use `pivot()`:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample data in long format\ndata = {'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n        'City': ['NY', 'LA', 'NY', 'LA'],\n        'Temperature': [32, 70, 35, 72]}\n\ndf_long = pd.DataFrame(data)\n\n# Pivot the data to wide format\ndf_wide = df_long.pivot(index='Date', columns='City', values='Temperature')","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.861887Z","iopub.execute_input":"2023-10-25T07:40:57.863192Z","iopub.status.idle":"2023-10-25T07:40:57.876404Z","shell.execute_reply.started":"2023-10-25T07:40:57.863142Z","shell.execute_reply":"2023-10-25T07:40:57.875377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_long","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.878238Z","iopub.execute_input":"2023-10-25T07:40:57.879060Z","iopub.status.idle":"2023-10-25T07:40:57.895086Z","shell.execute_reply.started":"2023-10-25T07:40:57.879014Z","shell.execute_reply":"2023-10-25T07:40:57.893891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_wide","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.897743Z","iopub.execute_input":"2023-10-25T07:40:57.898292Z","iopub.status.idle":"2023-10-25T07:40:57.914842Z","shell.execute_reply.started":"2023-10-25T07:40:57.898242Z","shell.execute_reply":"2023-10-25T07:40:57.913690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this example, `pivot()` is used to pivot the data from a long format where temperatures for different cities are in rows to a wide format where each city has its own column.\n\nThese functions are valuable for data preprocessing and reshaping when the format of your data needs to change to suit your analysis or visualization requirements.","metadata":{}},{"cell_type":"markdown","source":"#### 13. **Handling Datetime Data**:\n\n    - Extracting date, time, and other components from datetime columns.\n    \n    Pandas provides several functions to handle datetime data, allowing you to extract date, time, and other components from datetime columns. Here are some common operations you can perform:\n\n**1. Extracting Date and Time Components:**\n\n- To extract the year, month, day, hour, minute, or second from a datetime column, you can use the `.dt` accessor along with the specific component you want to extract. Here are some examples:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample DataFrame with a datetime column\ndata = {'Date': ['2023-10-24 08:30:00', '2023-10-24 14:45:00']}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Extract year, month, and day\ndf['Year'] = df['Date'].dt.year\ndf['Month'] = df['Date'].dt.month\ndf['Month_name'] = pd.to_datetime(df['Date']).dt.month_name()\ndf['Day'] = df['Date'].dt.day\n\n# Extract hour and minute\ndf['Hour'] = df['Date'].dt.hour\ndf['Minute'] = df['Date'].dt.minute","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.916355Z","iopub.execute_input":"2023-10-25T07:40:57.916845Z","iopub.status.idle":"2023-10-25T07:40:57.935766Z","shell.execute_reply.started":"2023-10-25T07:40:57.916798Z","shell.execute_reply":"2023-10-25T07:40:57.934811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.937092Z","iopub.execute_input":"2023-10-25T07:40:57.938250Z","iopub.status.idle":"2023-10-25T07:40:57.959555Z","shell.execute_reply.started":"2023-10-25T07:40:57.938210Z","shell.execute_reply":"2023-10-25T07:40:57.958155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Extracting Weekday:**\n\n- To extract the day of the week (e.g., Monday, Tuesday), you can use `.dt.weekday_name` or `.dt.day_name()`. This function works well if the datetime column is of type datetime.","metadata":{}},{"cell_type":"code","source":"# Extract weekday\ndf['Weekday'] = df['Date'].dt.day_name()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.961409Z","iopub.execute_input":"2023-10-25T07:40:57.962206Z","iopub.status.idle":"2023-10-25T07:40:57.981956Z","shell.execute_reply.started":"2023-10-25T07:40:57.962158Z","shell.execute_reply":"2023-10-25T07:40:57.980424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Extracting Date Differences:**\n\n- You can calculate the difference between two datetime columns, such as days, using the subtraction operator.","metadata":{}},{"cell_type":"code","source":"# Calculate the date difference in days\ndf['Date2'] = pd.to_datetime(['2023-10-25', '2023-10-26'])\ndf['DateDifference'] = (df['Date2'] - df['Date']).dt.days\ndf","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:57.983363Z","iopub.execute_input":"2023-10-25T07:40:57.984221Z","iopub.status.idle":"2023-10-25T07:40:58.003379Z","shell.execute_reply.started":"2023-10-25T07:40:57.984175Z","shell.execute_reply":"2023-10-25T07:40:58.001905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are just a few examples of how to handle datetime data in Pandas. You can use various datetime-related attributes and methods to manipulate datetime columns to suit your specific analysis and reporting needs.","metadata":{}},{"cell_type":"markdown","source":"14. **Handling Categorical Data**:\n\n    - Encoding categorical variables into numerical format.","metadata":{}},{"cell_type":"markdown","source":"Handling categorical data often involves encoding categorical variables into numerical format so that they can be used in machine learning models or other data analysis tasks. Pandas provides several methods for encoding categorical data, and scikit-learn offers additional tools for preprocessing categorical data. Here are some common techniques:\n\n**1. Pandas `pd.get_dummies()`:**\n\n`pd.get_dummies()` is a method to perform one-hot encoding, which creates binary columns for each category in the original categorical variable.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample DataFrame with a categorical column\ndata = {'Category': ['A', 'B', 'A', 'C', 'B']}\ndf = pd.DataFrame(data)\n\n# Perform one-hot encoding\ndf_encoded = pd.get_dummies(df, columns=['Category'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.004934Z","iopub.execute_input":"2023-10-25T07:40:58.005698Z","iopub.status.idle":"2023-10-25T07:40:58.015419Z","shell.execute_reply.started":"2023-10-25T07:40:58.005662Z","shell.execute_reply":"2023-10-25T07:40:58.014167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.017191Z","iopub.execute_input":"2023-10-25T07:40:58.018283Z","iopub.status.idle":"2023-10-25T07:40:58.035472Z","shell.execute_reply.started":"2023-10-25T07:40:58.018216Z","shell.execute_reply":"2023-10-25T07:40:58.034311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_encoded","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.042466Z","iopub.execute_input":"2023-10-25T07:40:58.043582Z","iopub.status.idle":"2023-10-25T07:40:58.055807Z","shell.execute_reply.started":"2023-10-25T07:40:58.043538Z","shell.execute_reply":"2023-10-25T07:40:58.054616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output will create binary columns for each category, representing whether the category is present or not.\n\n**2. Scikit-Learn Label Encoding:**\n\nScikit-learn provides the `LabelEncoder` to convert categorical values into numerical labels.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['CategoryEncoded'] = le.fit_transform(df['Category'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.057745Z","iopub.execute_input":"2023-10-25T07:40:58.058147Z","iopub.status.idle":"2023-10-25T07:40:58.071440Z","shell.execute_reply.started":"2023-10-25T07:40:58.058114Z","shell.execute_reply":"2023-10-25T07:40:58.069899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['CategoryEncoded']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.073117Z","iopub.execute_input":"2023-10-25T07:40:58.073993Z","iopub.status.idle":"2023-10-25T07:40:58.089662Z","shell.execute_reply.started":"2023-10-25T07:40:58.073910Z","shell.execute_reply":"2023-10-25T07:40:58.088269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This method assigns a unique integer to each category.\n\n**3. Scikit-Learn One-Hot Encoding:**\n\nScikit-learn also provides the `OneHotEncoder` to perform one-hot encoding.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\nencoded_data = encoder.fit_transform(df['Category'].values.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.091251Z","iopub.execute_input":"2023-10-25T07:40:58.092002Z","iopub.status.idle":"2023-10-25T07:40:58.104558Z","shell.execute_reply.started":"2023-10-25T07:40:58.091905Z","shell.execute_reply":"2023-10-25T07:40:58.103305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The resulting `encoded_data` is a sparse matrix that can be converted back to a DataFrame if needed.\n\nThe choice of encoding method depends on the specific requirements of your analysis or machine learning model. One-hot encoding is suitable when there is no ordinal relationship between categories, while label encoding can be useful when an ordinal relationship exists between categories.\n\n**4. Pandas `pd.Categorical`:**\n\nPandas provides the `pd.Categorical` data type that can be used to efficiently encode and manage categorical data. You can convert a column to a `Categorical` data type and then access its codes.","metadata":{}},{"cell_type":"code","source":"df['Category'] = pd.Categorical(df['Category'])\ndf['CategoryEncoded'] = df['Category'].cat.codes\ndf['CategoryEncoded']","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.107003Z","iopub.execute_input":"2023-10-25T07:40:58.107408Z","iopub.status.idle":"2023-10-25T07:40:58.123939Z","shell.execute_reply.started":"2023-10-25T07:40:58.107375Z","shell.execute_reply":"2023-10-25T07:40:58.122482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This approach is useful when you want to work with the original categorical values but also have access to their encoded versions.\n\nHandling categorical data is an essential step in data preprocessing, and the choice of encoding method can impact the performance of machine learning models. Make sure to choose the appropriate method based on the characteristics of your data and the requirements of your analysis.","metadata":{}},{"cell_type":"markdown","source":"15. **Mathematical and Statistical Transformations**:\n\n    - `df.apply()`: Apply mathematical or statistical functions row-wise or column-wise.\n    \n    \n    In Pandas, you can perform mathematical and statistical transformations using the `df.apply()` method. This method allows you to apply a custom function, a built-in NumPy function, or a statistical function row-wise or column-wise to a DataFrame. Here's how you can use `df.apply()` for such transformations:\n\n**1. Applying a Custom Function:**\n\nYou can define your own custom function and use `df.apply()` to apply it to each row or column of the DataFrame. Here's an example that calculates the square of each element in a DataFrame:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Define a custom function to calculate the square\ndef square(x):\n    return x ** 2\n\n# Apply the custom function to each element in the DataFrame\ndf_squared = df.apply(square)\n\ndf_squared","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.125345Z","iopub.execute_input":"2023-10-25T07:40:58.125790Z","iopub.status.idle":"2023-10-25T07:40:58.143465Z","shell.execute_reply.started":"2023-10-25T07:40:58.125755Z","shell.execute_reply":"2023-10-25T07:40:58.142354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Applying Built-in NumPy Functions:**\n\nYou can apply NumPy functions using `df.apply()` as well. For example, to calculate the mean of each column:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Apply NumPy's mean function to each column\ncolumn_means = df.apply(np.mean)\ncolumn_means","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.145169Z","iopub.execute_input":"2023-10-25T07:40:58.146456Z","iopub.status.idle":"2023-10-25T07:40:58.161270Z","shell.execute_reply.started":"2023-10-25T07:40:58.146404Z","shell.execute_reply":"2023-10-25T07:40:58.159956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Applying Statistical Functions:**\n\nYou can use statistical functions like `mean()`, `sum()`, `min()`, `max()`, etc., directly with `df.apply()` to compute statistics row-wise or column-wise. For example, to calculate the sum of each row:","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Calculate the sum of each row\nrow_sums = df.apply(sum, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.162856Z","iopub.execute_input":"2023-10-25T07:40:58.163251Z","iopub.status.idle":"2023-10-25T07:40:58.172502Z","shell.execute_reply.started":"2023-10-25T07:40:58.163219Z","shell.execute_reply":"2023-10-25T07:40:58.171236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.174125Z","iopub.execute_input":"2023-10-25T07:40:58.174826Z","iopub.status.idle":"2023-10-25T07:40:58.193381Z","shell.execute_reply.started":"2023-10-25T07:40:58.174790Z","shell.execute_reply":"2023-10-25T07:40:58.192416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_sums","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.194613Z","iopub.execute_input":"2023-10-25T07:40:58.195227Z","iopub.status.idle":"2023-10-25T07:40:58.212580Z","shell.execute_reply.started":"2023-10-25T07:40:58.195180Z","shell.execute_reply":"2023-10-25T07:40:58.211198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `axis` parameter specifies whether the function should be applied row-wise (axis=1) or column-wise (axis=0).\n\n`df.apply()` is a versatile method that allows you to perform a wide range of mathematical and statistical transformations on DataFrames, making it a valuable tool for data analysis and manipulation.","metadata":{}},{"cell_type":"markdown","source":"16. **Custom Data Cleaning and Transformation**:\n\n    - Writing custom functions and transformations to address domain-specific needs.\n    \n    In Pandas, you can perform mathematical and statistical transformations using the `df.apply()` method. This method allows you to apply a custom function, a built-in NumPy function, or a statistical function row-wise or column-wise to a DataFrame. Here's how you can use `df.apply()` for such transformations:\n\n**1. Applying a Custom Function:**\n\nYou can define your own custom function and use `df.apply()` to apply it to each row or column of the DataFrame. Here's an example that calculates the square of each element in a DataFrame:","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Define a custom function to calculate the square\ndef square(x):\n    return x ** 2\n\n# Apply the custom function to each element in the DataFrame\ndf_squared = df.apply(square)\n\nprint(df_squared)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.214516Z","iopub.execute_input":"2023-10-25T07:40:58.214991Z","iopub.status.idle":"2023-10-25T07:40:58.230753Z","shell.execute_reply.started":"2023-10-25T07:40:58.214938Z","shell.execute_reply":"2023-10-25T07:40:58.229729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Applying Built-in NumPy Functions:**\n\nYou can apply NumPy functions using `df.apply()` as well. For example, to calculate the mean of each column:","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Apply NumPy's mean function to each column\ncolumn_means = df.apply(np.mean)\n\nprint(column_means)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.232391Z","iopub.execute_input":"2023-10-25T07:40:58.233635Z","iopub.status.idle":"2023-10-25T07:40:58.245047Z","shell.execute_reply.started":"2023-10-25T07:40:58.233586Z","shell.execute_reply":"2023-10-25T07:40:58.243773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Applying Statistical Functions:**\n\nYou can use statistical functions like `mean()`, `sum()`, `min()`, `max()`, etc., directly with `df.apply()` to compute statistics row-wise or column-wise. For example, to calculate the sum of each row:","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\n\n# Sample DataFrame\ndata = {'A': [1, 2, 3, 4],\n        'B': [5, 6, 7, 8]}\ndf = pd.DataFrame(data)\n\n# Calculate the sum of each row\nrow_sums = df.apply(sum, axis=1)\n\nprint(row_sums)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.246695Z","iopub.execute_input":"2023-10-25T07:40:58.247591Z","iopub.status.idle":"2023-10-25T07:40:58.263175Z","shell.execute_reply.started":"2023-10-25T07:40:58.247554Z","shell.execute_reply":"2023-10-25T07:40:58.261868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `axis` parameter specifies whether the function should be applied row-wise (axis=1) or column-wise (axis=0).\n\n`df.apply()` is a versatile method that allows you to perform a wide range of mathematical and statistical transformations on DataFrames, making it a valuable tool for data analysis and manipulation.","metadata":{}},{"cell_type":"markdown","source":"Data cleaning and transformation are highly dependent on the specific dataset and analysis goals. Pandas offers a wide range of functions to support these operations, allowing you to preprocess and manipulate data effectively before analysis.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Convert an integer to a Timedelta (in this case, 5 days)\ntimedelta = pd.to_timedelta(5, unit='D')\n\n# Convert a string to a Timedelta (e.g., '3 days 12:30:15')\ntimedelta_str = pd.to_timedelta('3 days 12 hours 30 minutes 15 seconds')\n\n# Convert a list or array of strings to a Series of Timedeltas\ntime_values = ['1 day', '2 days', '4 hours']\ntimedeltas = pd.to_timedelta(time_values)\n\n# Perform arithmetic operations with Timedeltas\ntotal_time = timedelta + timedelta_str","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.264834Z","iopub.execute_input":"2023-10-25T07:40:58.265267Z","iopub.status.idle":"2023-10-25T07:40:58.273844Z","shell.execute_reply.started":"2023-10-25T07:40:58.265234Z","shell.execute_reply":"2023-10-25T07:40:58.272990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_time","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.275525Z","iopub.execute_input":"2023-10-25T07:40:58.276376Z","iopub.status.idle":"2023-10-25T07:40:58.295311Z","shell.execute_reply.started":"2023-10-25T07:40:58.276332Z","shell.execute_reply":"2023-10-25T07:40:58.293877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's walk through some examples of using the `groupby()` method in Pandas with code to illustrate its various features:\n\n**1. Grouping and Aggregating Data:**\n\n```python\nimport pandas as pd\n\n# Creating a sample DataFrame\ndata = {'Category': ['A', 'B', 'A', 'B', 'A'],\n        'Value': [10, 20, 15, 25, 30]}\ndf = pd.DataFrame(data)\n\n# Grouping by 'Category' and calculating the sum of 'Value'\ngrouped = df.groupby('Category')['Value'].sum()\nprint(grouped)\n```\n\n**2. Chaining Aggregation Functions:**\n\n```python\n# Grouping by 'Category' and calculating multiple aggregations\nagg_result = df.groupby('Category')['Value'].agg(['sum', 'mean', 'count'])\nprint(agg_result)\n```\n\n**3. Custom Aggregation Functions:**\n\n```python\n# Define a custom aggregation function to calculate range\ncustom_agg = lambda x: x.max() - x.min()\ncustom_result = df.groupby('Category')['Value'].agg(custom_agg)\nprint(custom_result)\n```\n\n**4. Named Aggregations:**\n\n```python\n# Assign a name to the result of an aggregation\nnamed_agg = df.groupby('Category').agg(total_value=('Value', 'sum'))\nprint(named_agg)\n```\n\n**5. Iterating Over Groups:**\n\n```python\n# Iterating over groups\nfor group_name, group_df in df.groupby('Category'):\n    print(f\"Group: {group_name}\")\n    print(group_df)\n```\n\n**6. Filtering Groups:**\n\n```python\n# Filtering groups based on a condition\nfiltered_groups = df.groupby('Category').filter(lambda x: x['Value'].sum() > 20)\nprint(filtered_groups)\n```\n\nThese examples demonstrate various ways to use the `groupby()` method for grouping, aggregating, and processing data in Pandas. You can apply these techniques to real-world data analysis tasks to gain insights and perform summarization on your data.","metadata":{"execution":{"iopub.status.busy":"2023-10-24T07:55:42.364881Z","iopub.execute_input":"2023-10-24T07:55:42.365325Z","iopub.status.idle":"2023-10-24T07:55:42.371670Z","shell.execute_reply.started":"2023-10-24T07:55:42.365290Z","shell.execute_reply":"2023-10-24T07:55:42.370071Z"}}},{"cell_type":"code","source":"ipl = pd.read_csv(\"/kaggle/input/ipl-auction-20132022-data/IPl Auction 2013-2022.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.297697Z","iopub.execute_input":"2023-10-25T07:40:58.298251Z","iopub.status.idle":"2023-10-25T07:40:58.314997Z","shell.execute_reply.started":"2023-10-25T07:40:58.298213Z","shell.execute_reply":"2023-10-25T07:40:58.313830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipl.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.316753Z","iopub.execute_input":"2023-10-25T07:40:58.318060Z","iopub.status.idle":"2023-10-25T07:40:58.335766Z","shell.execute_reply.started":"2023-10-25T07:40:58.318010Z","shell.execute_reply":"2023-10-25T07:40:58.334485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp = ipl.groupby(by=\"nationality\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.337979Z","iopub.execute_input":"2023-10-25T07:40:58.338971Z","iopub.status.idle":"2023-10-25T07:40:58.349718Z","shell.execute_reply.started":"2023-10-25T07:40:58.338887Z","shell.execute_reply":"2023-10-25T07:40:58.348678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.first()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.358377Z","iopub.execute_input":"2023-10-25T07:40:58.358857Z","iopub.status.idle":"2023-10-25T07:40:58.380801Z","shell.execute_reply.started":"2023-10-25T07:40:58.358822Z","shell.execute_reply":"2023-10-25T07:40:58.379440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.last()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.382242Z","iopub.execute_input":"2023-10-25T07:40:58.383792Z","iopub.status.idle":"2023-10-25T07:40:58.399479Z","shell.execute_reply.started":"2023-10-25T07:40:58.383732Z","shell.execute_reply":"2023-10-25T07:40:58.398137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.describe()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.403196Z","iopub.execute_input":"2023-10-25T07:40:58.403820Z","iopub.status.idle":"2023-10-25T07:40:58.463291Z","shell.execute_reply.started":"2023-10-25T07:40:58.403758Z","shell.execute_reply":"2023-10-25T07:40:58.461965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.groups.keys()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.464891Z","iopub.execute_input":"2023-10-25T07:40:58.465402Z","iopub.status.idle":"2023-10-25T07:40:58.474420Z","shell.execute_reply.started":"2023-10-25T07:40:58.465356Z","shell.execute_reply":"2023-10-25T07:40:58.472949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.476415Z","iopub.execute_input":"2023-10-25T07:40:58.477265Z","iopub.status.idle":"2023-10-25T07:40:58.502490Z","shell.execute_reply.started":"2023-10-25T07:40:58.477213Z","shell.execute_reply":"2023-10-25T07:40:58.501343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Overseas\")","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.504642Z","iopub.execute_input":"2023-10-25T07:40:58.505133Z","iopub.status.idle":"2023-10-25T07:40:58.525870Z","shell.execute_reply.started":"2023-10-25T07:40:58.505089Z","shell.execute_reply":"2023-10-25T07:40:58.524652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")['sold_price'].count()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.527766Z","iopub.execute_input":"2023-10-25T07:40:58.528155Z","iopub.status.idle":"2023-10-25T07:40:58.537670Z","shell.execute_reply.started":"2023-10-25T07:40:58.528122Z","shell.execute_reply":"2023-10-25T07:40:58.535425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")['sold_price'].sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.539789Z","iopub.execute_input":"2023-10-25T07:40:58.540236Z","iopub.status.idle":"2023-10-25T07:40:58.550983Z","shell.execute_reply.started":"2023-10-25T07:40:58.540200Z","shell.execute_reply":"2023-10-25T07:40:58.549777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")['sold_price'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.553069Z","iopub.execute_input":"2023-10-25T07:40:58.555235Z","iopub.status.idle":"2023-10-25T07:40:58.566433Z","shell.execute_reply.started":"2023-10-25T07:40:58.555194Z","shell.execute_reply":"2023-10-25T07:40:58.565518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")['sold_price'].max()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.567454Z","iopub.execute_input":"2023-10-25T07:40:58.567806Z","iopub.status.idle":"2023-10-25T07:40:58.579574Z","shell.execute_reply.started":"2023-10-25T07:40:58.567775Z","shell.execute_reply":"2023-10-25T07:40:58.578615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nation_grp.get_group(\"Indian\")['sold_price'].min()","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.581370Z","iopub.execute_input":"2023-10-25T07:40:58.581709Z","iopub.status.idle":"2023-10-25T07:40:58.595278Z","shell.execute_reply.started":"2023-10-25T07:40:58.581680Z","shell.execute_reply":"2023-10-25T07:40:58.594149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ipl.groupby(\"type\")['sold_price'].agg(['min','max','sum', 'mean', 'count'])","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.597007Z","iopub.execute_input":"2023-10-25T07:40:58.597660Z","iopub.status.idle":"2023-10-25T07:40:58.620654Z","shell.execute_reply.started":"2023-10-25T07:40:58.597613Z","shell.execute_reply":"2023-10-25T07:40:58.619135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name,df in nation_grp:\n    print(name)\n    print(df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-25T07:40:58.624753Z","iopub.execute_input":"2023-10-25T07:40:58.625252Z","iopub.status.idle":"2023-10-25T07:40:58.633154Z","shell.execute_reply.started":"2023-10-25T07:40:58.625218Z","shell.execute_reply":"2023-10-25T07:40:58.631459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Conclusion\n\nIn this comprehensive tutorial, we've covered a wide range of topics related to data manipulation and analysis using the Pandas library in Python. Whether you're a beginner or an experienced data analyst, Pandas is an invaluable tool for working with structured data effectively. With Pandas, you can load, clean, transform, and analyze data, making it a fundamental library for any data-driven project.\n\nWe explored the following key aspects of Pandas:\n\n1. **Introduction to Pandas:** We started with an overview of what Pandas is and why it's so popular for data analysis and manipulation.\n\n2. **Data Structures:** We delved into the two primary data structures in Pandas: Series and DataFrames. These structures are the building blocks for working with data.\n\n3. **Data Cleaning:** We discussed techniques for handling missing data, duplications, and outliers, which are crucial for preparing data for analysis.\n\n4. **Data Transformation:** We explored various techniques for reshaping data, creating new columns, and combining DataFrames.\n\n5. **Grouping and Aggregation:** We demonstrated how to group data and perform aggregation operations using Pandas.\n\n6. **Reading and Writing Data:** You learned how to read data from various file formats and save your Pandas DataFrames to different formats.\n\n7. **Data Visualization:** We discussed how to create basic data visualizations with Pandas and Matplotlib.\n\n8. **Custom Functions and Transformations:** You learned how to write and apply custom functions for data cleaning, transformation, and analysis.\n\nThroughout the tutorial, we provided practical examples to help you understand how to use Pandas effectively. Remember that Pandas is a versatile library, and as you become more familiar with its capabilities, you'll be better equipped to handle real-world data analysis tasks.\n\nWe hope this tutorial has been a valuable resource in your journey to become proficient with Pandas. Data manipulation and analysis are foundational skills for many domains, including data science, machine learning, finance, and more. Continue exploring and experimenting with Pandas to build your expertise and take your data analysis skills to the next level.\n\nIf you have any questions or need further assistance in the future, feel free to return. Happy coding and data analyzing!\n\n---\n\nThank you for going through this Pandas tutorial, and we wish you the best in your data analysis endeavors!","metadata":{}}]}